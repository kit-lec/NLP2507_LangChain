{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c1858a1-5601-44a1-8923-ccaa3b8fbdf6",
   "metadata": {},
   "source": [
    "# PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f31d0-374c-4840-8bc0-df865654b2c4",
   "metadata": {},
   "source": [
    "# Langchain (v0.3) 의 주요 Components\n",
    "https://python.langchain.com/docs/how_to/#components\n",
    "\n",
    "1. Chat models\n",
    "- Chat model 은 '메시지'를 입력받아 출력하는 형태의 언어 모델. \n",
    "\n",
    "1. Messages\n",
    "\n",
    "1. Prompt templates\n",
    "\n",
    "1. Example selectors\n",
    "\n",
    "1. LLMs\n",
    "\n",
    "1. Output parsers\n",
    "\n",
    "1. Document loaders\n",
    "\n",
    "1. Text splitters\n",
    "\n",
    "1. Embedding models\n",
    "\n",
    "1. Vector stores\n",
    "\n",
    "1. Retrievers\n",
    "\n",
    "\n",
    "1. Chains\n",
    "https://python.langchain.com/docs/versions/migrating_chains/\n",
    "\n",
    "\n",
    "1. Agents\n",
    "\n",
    "1. Memory\n",
    "\n",
    "1. Callbakcs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7db13c-5851-411a-91aa-047cf265f697",
   "metadata": {},
   "source": [
    "# API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d057639b-c7f3-4f5f-a183-3463b4be569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "sk-proj-iKU13YeoxNgF...\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(load_dotenv())\n",
    "\n",
    "print(f'{os.environ['OPENAI_API_KEY'][:20]}...')  # 확인용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c847798-3d85-4a48-997a-0504847c7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "prompts class 계층도\n",
    "\n",
    "BasePromptTemplate --> PipelinePromptTemplate\n",
    "                       StringPromptTemplate --> PromptTemplate\n",
    "                                                FewShotPromptTemplate\n",
    "                                                FewShotPromptWithTemplates\n",
    "                       BaseChatPromptTemplate --> AutoGPTPrompt\n",
    "                                                  ChatPromptTemplate --> AgentScratchPadChatPromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "BaseMessagePromptTemplate --> MessagesPlaceholder\n",
    "                              BaseStringMessagePromptTemplate --> ChatMessagePromptTemplate\n",
    "                                                                  HumanMessagePromptTemplate\n",
    "                                                                  AIMessagePromptTemplate\n",
    "                                                                  SystemMessagePromptTemplate\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245b37d1-a370-471a-a7ea-665701aa6de7",
   "metadata": {},
   "source": [
    "# 0.PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0552171d-20e0-40c8-9de1-faee50cd4954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.llms.base import OpenAI\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ede0b9d2-e36d-42d4-9967-f5bce47777d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(\n",
    "    temperature=0.1,\n",
    "    streaming=True,\n",
    "    callbacks=[\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e179f33a-61f8-4ca3-82f5-40b69d9f349c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of France'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PromptTemplate\n",
    "# 방법1\n",
    "t = PromptTemplate.from_template(\"What is the capital of {country}\")\n",
    "t.format(country = \"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a2928c-7a12-42b9-97c2-aa3f5df5162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 템플릿을 만드는 이점 또 한가지!\n",
    "# prompt template 을 디스크에 '저장'하고 'load' 할 수 있기 떼문이다.\n",
    "\n",
    "# 나중에 LLM 다룰때 prompt 는 매우 중요합니다.\n",
    "# 대규모 프로젝트에서는 \n",
    "# - 'prompt 만 만드는 팀'이 있고\n",
    "# - '코딩하는 팀'이 따로 있을것이다.  \n",
    "#    데이터베이스나 파일 등에 만들어 저장해 놓은 prompt 를 load 해야 할겁니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c14ce0-3081-4173-89ad-bc40e073e478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of France'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 방법2\n",
    "t2 = PromptTemplate(\n",
    "    template = \"What is the capital of {country}\",\n",
    "    input_variables=['country'],  # 입력변수를 직접 명시\n",
    ")\n",
    "t2.format(country = \"France\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc537c-c3f2-43c8-9908-179571b02ea4",
   "metadata": {},
   "source": [
    "# 1.FewShotPromptTemplate\n",
    "모델에 예제(example) 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1bf4c2-df49-4a6d-8766-233d1c0553c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에게 '어떻게 대답해야 하는 지에 대한 예제(example)'를 AI 모델에게 주는 것이\n",
    "# prompt 를 사용해서 '어떻게 대답해야 하는지 알려주는 것'보다 훨씬 좋다\n",
    "\n",
    "# FewShotPromptTemplate 이 하는 일이 바로 그거다!\n",
    "# - 이를 통해 예제(샘플)를 형식화(포맷) 할수 있다.\n",
    "# - 이런 예제들을 데이터베이스등에 저장시켜놓고 활용할수도 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51081c12-16f3-4c19-99b8-741514ec639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5b55a8d-96d4-4f05-87c3-917a263e6f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ↓ 이 예제들은\n",
    "# 모델이 나에게 '이런 식으로 답변해 줬으면 좋겠다' 라고 제시하는 example(예제) 들.\n",
    "\n",
    "examples = [\n",
    "  {\n",
    "    \"question\": \"What do you know about France?\",\n",
    "\n",
    "    # ↓ 원하는 형식의 답변 이다..\n",
    "    \"answer\": \"\"\"\n",
    "      Here is what I know:\n",
    "      Capital: Paris\n",
    "      Language: French\n",
    "      Food: Wine and Cheese\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What do you know about Italy?\",\n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Rome\n",
    "      Language: Italian\n",
    "      Food: Pizza and Pasta\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What do you know about Greece?\",\n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Athens\n",
    "      Language: Greek\n",
    "      Food: Souvlaki and Feta Cheese\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1275f0d4-20fd-4a78-b3a9-cb907cd8c419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "France is a country located in Western Europe. It is known for its rich history, culture, and cuisine. The capital city is Paris, which is famous for landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral.\n",
      "\n",
      "France is the largest country in the European Union by land area and the third-largest in Europe overall. It has a population of over 67 million people. The official language is French, and the currency is the Euro.\n",
      "\n",
      "France is a popular tourist destination, attracting millions of visitors each year to its beautiful cities, countryside, and beaches. The country is also known for its wine and cheese production, fashion industry, and art and literature.\n",
      "\n",
      "France has a long history of political and cultural influence, including the French Revolution, the Napoleonic Wars, and the establishment of the French colonial empire. Today, France is a member of the United Nations, NATO, and the European Union, among other international organizations."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='France is a country located in Western Europe. It is known for its rich history, culture, and cuisine. The capital city is Paris, which is famous for landmarks such as the Eiffel Tower, Louvre Museum, and Notre-Dame Cathedral.\\n\\nFrance is the largest country in the European Union by land area and the third-largest in Europe overall. It has a population of over 67 million people. The official language is French, and the currency is the Euro.\\n\\nFrance is a popular tourist destination, attracting millions of visitors each year to its beautiful cities, countryside, and beaches. The country is also known for its wine and cheese production, fashion industry, and art and literature.\\n\\nFrance has a long history of political and cultural influence, including the French Revolution, the Napoleonic Wars, and the establishment of the French colonial empire. Today, France is a member of the United Nations, NATO, and the European Union, among other international organizations.', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run--0ed3eb8c-b9f8-484b-ba6f-abec4d343c77-0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 예제 없이 모델 호출하면?\n",
    "chat.invoke(\"What do you know about France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2abf43d9-08ae-42ce-a50d-a4c0d7a0f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template = \"\"\"\n",
    "    Human: {question}\n",
    "    AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# {question}, {answer} 는 위 example 과 동일한 key 를 사용하여 포맷 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "416ed690-58d8-4b5e-bec2-07864f325651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['answer', 'question'], input_types={}, partial_variables={}, template='\\n    Human: {question}\\n    AI: {answer}\\n')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db2ec124-45a9-492b-9ffe-47435116c002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Human: What do you know about Greece?\n",
      "    AI: \n",
      "      I know this:\n",
      "      Capital: Athens\n",
      "      Language: Greek\n",
      "      Food: Souvlaki and Feta Cheese\n",
      "      Currency: Euro\n",
      "      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(example_prompt.format(**examples[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee38c60a-0ae5-4c1f-932b-7c60209e1d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotPromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, examples=[{'question': 'What do you know about France?', 'answer': '\\n      Here is what I know:\\n      Capital: Paris\\n      Language: French\\n      Food: Wine and Cheese\\n      Currency: Euro\\n      '}, {'question': 'What do you know about Italy?', 'answer': '\\n      I know this:\\n      Capital: Rome\\n      Language: Italian\\n      Food: Pizza and Pasta\\n      Currency: Euro\\n      '}, {'question': 'What do you know about Greece?', 'answer': '\\n      I know this:\\n      Capital: Athens\\n      Language: Greek\\n      Food: Souvlaki and Feta Cheese\\n      Currency: Euro\\n      '}], example_prompt=PromptTemplate(input_variables=['answer', 'question'], input_types={}, partial_variables={}, template='\\n    Human: {question}\\n    AI: {answer}\\n'), suffix='Human: What do you know about {country}?')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,  # 사용할 prompt\n",
    "    examples=examples,  # 준비된 예제들\n",
    "\n",
    "    # 유저의 질문을 넣어보자.\n",
    "    \n",
    "    # suffix=\n",
    "    # 형식화된 모든 예제 마지막에 나오는 내용.\n",
    "    # 그래서 한번 다 형식화가 끝난 다음, 사용자의 질문은 무엇인지 나옵니다\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=['country']\n",
    ")\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4189d6f-fe9e-4bf3-9917-7fa11d6436da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Human: What do you know about France?\n",
      "    AI: \n",
      "      Here is what I know:\n",
      "      Capital: Paris\n",
      "      Language: French\n",
      "      Food: Wine and Cheese\n",
      "      Currency: Euro\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "    Human: What do you know about Italy?\n",
      "    AI: \n",
      "      I know this:\n",
      "      Capital: Rome\n",
      "      Language: Italian\n",
      "      Food: Pizza and Pasta\n",
      "      Currency: Euro\n",
      "      \n",
      "\n",
      "\n",
      "\n",
      "    Human: What do you know about Greece?\n",
      "    AI: \n",
      "      I know this:\n",
      "      Capital: Athens\n",
      "      Language: Greek\n",
      "      Food: Souvlaki and Feta Cheese\n",
      "      Currency: Euro\n",
      "      \n",
      "\n",
      "\n",
      "Human: What do you know about Germany?\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(country=\"Germany\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745faefb-e2bc-4e9f-a136-dce9a95eca12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1  example 리스트를 만들고   examples\n",
    "# step2  FewShotPromptTemplate 에 전달했고 examples=\n",
    "# step3  어떻게 전달한 예제들을 형식화 할지 알려주었고\n",
    "# step4  마지막에 질문을 포함시켰다.  suffix, input_variables\n",
    "\n",
    "# AI 는 우리의 예제들과 똑같은 구조, 형태로 답변하게 될겁니다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92a72843-1016-40fc-88ca-8f24b9e23328",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66afd683-82a5-462b-906f-5174837167dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "      Here is what I know:\n",
      "      Capital: Berlin\n",
      "      Language: German\n",
      "      Food: Bratwurst and Sauerkraut\n",
      "      Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI: \\n      Here is what I know:\\n      Capital: Berlin\\n      Language: German\\n      Food: Bratwurst and Sauerkraut\\n      Currency: Euro', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run--5f2befde-ff90-46be-81fa-6b350139aa31-0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'country': 'Germany'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7437ddcd-a832-4045-b34a-8c83b80ea084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "      Here is what I know:\n",
      "      Capital: Ankara\n",
      "      Language: Turkish\n",
      "      Food: Kebab and Baklava\n",
      "      Currency: Turkish Lira"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI: \\n      Here is what I know:\\n      Capital: Ankara\\n      Language: Turkish\\n      Food: Kebab and Baklava\\n      Currency: Turkish Lira', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run--666754e9-3b0f-4bcd-bb3c-54312298bd36-0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'country': 'Turkey'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68bde75-9fa3-4cbb-84de-f37388873e51",
   "metadata": {},
   "source": [
    "# 2.FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e995f77-5486-483e-83ed-ac39b6c8e7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.chat import ChatPromptTemplate\n",
    "from langchain_core.prompts.few_shot import FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3a9018e-5ce3-44a1-89ac-a8a697a80f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "  {\n",
    "    \"country\": \"France\",\n",
    "\n",
    "    \"answer\": \"\"\"\n",
    "      Here is what I know:\n",
    "      Capital: Paris\n",
    "      Language: French\n",
    "      Food: Wine and Cheese\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"country\": \"Italy\",\n",
    "      \n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Rome\n",
    "      Language: Italian\n",
    "      Food: Pizza and Pasta\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"country\": \"Greece\",\n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Athens\n",
    "      Language: Greek\n",
    "      Food: Souvlaki and Feta Cheese\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a901f18-e17a-42ec-bf8f-acc3e386a3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    # examples 의 key 와 동일한 이름의 변수로!\n",
    "    (\"human\", \"What do you know abount {country}?\"),\n",
    "    (\"ai\", \"{answer}\"),\n",
    "])\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples= examples,\n",
    "\n",
    "    # suffix= 등은 필요없다.\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert, you give short answers.\"),\n",
    "    example_prompt,  ## !!\n",
    "    (\"human\", \"What do you know about {country}?\"), \n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "402ceb42-5ea2-4457-aed5-34f099debef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a geography expert, you give short answers.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What do you know abount France?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='\\n      Here is what I know:\\n      Capital: Paris\\n      Language: French\\n      Food: Wine and Cheese\\n      Currency: Euro\\n      ', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What do you know abount Italy?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='\\n      I know this:\\n      Capital: Rome\\n      Language: Italian\\n      Food: Pizza and Pasta\\n      Currency: Euro\\n      ', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What do you know abount Greece?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='\\n      I know this:\\n      Capital: Athens\\n      Language: Greek\\n      Food: Souvlaki and Feta Cheese\\n      Currency: Euro\\n      ', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='What do you know about Germany?', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prompt.format_messages(country=\"Germany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c008c169-f35c-4fe0-8c72-a084e34392b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = final_prompt | chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "be7eab48-1c3f-4011-96fa-4fbf69e90ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      I know this:\n",
      "      Capital: Berlin\n",
      "      Language: German\n",
      "      Food: Bratwurst and Sauerkraut\n",
      "      Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n      I know this:\\n      Capital: Berlin\\n      Language: German\\n      Food: Bratwurst and Sauerkraut\\n      Currency: Euro', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run--faf3b42e-21dc-4c9c-9ffe-5584e2354cfd-0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'country': 'Germany'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f52205c8-5ee0-4fd5-a23f-03c7832dde2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      I know this:\n",
      "      Capital: Seoul\n",
      "      Language: Korean\n",
      "      Food: Kimchi and Bibimbap\n",
      "      Currency: South Korean Won\n",
      "      "
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n      I know this:\\n      Capital: Seoul\\n      Language: Korean\\n      Food: Kimchi and Bibimbap\\n      Currency: South Korean Won\\n      ', additional_kwargs={}, response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run--618fbd23-b5a6-464c-98b8-b9102c1275b6-0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'country': 'South Korea'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18747d7-a5b4-4729-adff-fd9c9f959ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  다음에는 '예제' 를 어떻게 선택하는지에 대해 배워보자.\n",
    "\n",
    "#  때로는 수천개의 예제를 가지고 있을텐데,  이를 모두 모델에게 줄수 없는 상황이 있을수 있다.\n",
    "#    이유1) 비용이 많이 든다..  많은 텍스트 땜에.\n",
    "#    이유2) '허용하는 범위' 라는게 있다 => 모~든 예제들을 모델에게 줄 수는 없다.  제한이 있다 (context window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd782d25-95b0-42ca-9687-23cffab78bbc",
   "metadata": {},
   "source": [
    "# 3.ExampleSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90819960-9331-4ee8-b192-6ebc5cb1e2dd",
   "metadata": {},
   "source": [
    "## LengthBasedExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d2690b88-dddb-4b38-9dee-2e0920541a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors.length_based import LengthBasedExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68b82756-08e6-4b72-831e-d142ea43bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LengthBasedExampleSelector 는 기본적으로\n",
    "# - 예제(example) 들을 형식화 할 수 있고\n",
    "# - 예제의 양이 얼마나 되는지를 확인할수 있다.\n",
    "\n",
    "# 그러면, 사용자가 설정해 놓은 세팅값에 따라 prompt 에 알맞은 예제를 골라준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2329e343-1c7a-4504-aafe-7ec498f27b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "  {\n",
    "    \"country\": \"France\",\n",
    "\n",
    "    \"answer\": \"\"\"\n",
    "      Here is what I know:\n",
    "      Capital: Paris\n",
    "      Language: French\n",
    "      Food: Wine and Cheese\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"country\": \"Italy\",\n",
    "      \n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Rome\n",
    "      Language: Italian\n",
    "      Food: Pizza and Pasta\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "  {\n",
    "    \"country\": \"Greece\",\n",
    "    \"answer\": \"\"\"\n",
    "      I know this:\n",
    "      Capital: Athens\n",
    "      Language: Greek\n",
    "      Food: Souvlaki and Feta Cheese\n",
    "      Currency: Euro\n",
    "      \"\"\",\n",
    "  },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21513ea7-0fe4-4827-bfd2-6515209ac812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['answer', 'country'], input_types={}, partial_variables={}, template='Human: {country}\\nAI: {answer}')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_prompt = PromptTemplate.from_template(\"Human: {country}\\nAI: {answer}\")\n",
    "\n",
    "example_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8758651-498f-4735-b3f4-1ab7347beab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,  # 포맷팅한 결과의 크기가 얼마나 되는지 알아야 하기에 example_prompt 도 필요\n",
    "    max_length=10,  # 예제의 양을 얼마나 허용할지 지정. max_length= 를 넘어가는 example 은 제외된다.\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    # examples= 대신 example_selector= 지정.\n",
    "    example_selector=example_selector,   # max_length= 값에 따라 example 의 양을 정해준다.\n",
    "\n",
    "    suffix=\"Human: What do you know about {country}\",\n",
    "    input_variables = ['country'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "879312d2-26d3-4d73-b047-495fff1c318e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What do you know about Brazil'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(country='Brazil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1c93b8-d3f4-4c33-86b0-71266122633d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ↑ 보다시피 선택된 예제가 없다!\n",
    "# ↑ example 들이 하나도 포맷팅이 안되어 있다??\n",
    "# max_length 값이 너무 작아서 exmaple 하나도 포맷팅 안됨.\n",
    "\n",
    "# ↓ max_length= 값을 변경해보자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d4d9b3b-21df-49e2-b8db-e5cdf6b43c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: France\n",
      "AI: \n",
      "      Here is what I know:\n",
      "      Capital: Paris\n",
      "      Language: French\n",
      "      Food: Wine and Cheese\n",
      "      Currency: Euro\n",
      "      \n",
      "\n",
      "Human: What do you know about Brazil\n"
     ]
    }
   ],
   "source": [
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=80,  # max_length 조정\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,   # max_length= 값에 따라 example 의 양을 정해준다.\n",
    "\n",
    "    suffix=\"Human: What do you know about {country}\",\n",
    "    input_variables = ['country'],\n",
    ")\n",
    "\n",
    "print(prompt.format(country='Brazil'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1607be0f-29df-4a78-a636-863b479d12fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: France\n",
      "AI: \n",
      "      Here is what I know:\n",
      "      Capital: Paris\n",
      "      Language: French\n",
      "      Food: Wine and Cheese\n",
      "      Currency: Euro\n",
      "      \n",
      "\n",
      "Human: Italy\n",
      "AI: \n",
      "      I know this:\n",
      "      Capital: Rome\n",
      "      Language: Italian\n",
      "      Food: Pizza and Pasta\n",
      "      Currency: Euro\n",
      "      \n",
      "\n",
      "Human: What do you know about Brazil\n"
     ]
    }
   ],
   "source": [
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=150,  # max_length 조정\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,   # max_length= 값에 따라 example 의 양을 정해준다.\n",
    "\n",
    "    suffix=\"Human: What do you know about {country}\",\n",
    "    input_variables = ['country'],\n",
    ")\n",
    "\n",
    "print(prompt.format(country='Brazil'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce220f30-865b-4bbd-9a7f-2b8d7a03beb1",
   "metadata": {},
   "source": [
    "## Custom ExampleSelector (BaseExampleSelector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b6b49-6363-4728-b6b2-04e28ee6e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ↓ 이제 자신만의 example selector 를 만드는 방법에 대해 배워보자\n",
    "# 이를 통해 내가 원하는 대로의 examples 들을 얼마나 허용할지 정할수 있게 될거다.\n",
    "\n",
    "# 가령, 애플리케이션에서 유저의 로그인 여부 또는 유저가 사용하는 언어에 따라\n",
    "# 얼마나 많은 examples 들을 허용할지 정할수도 있는 것이다.\n",
    "\n",
    "# 여기선 RandomExampleSelector 라는 이름의 ExampleSelector 를 를 '직접' 만들어 사용해 볼거다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ece4a157-82ee-437d-bc31-5a1a228c3b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.example_selectors.base import BaseExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab9191be-06b4-4986-bfdb-4283c3ce9632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseExampleSelector 의 구현객체를 만드려면\n",
    "#  상속 받은뒤 select_examples() 과 add_example() 을 반드시 오버라이딩 해주어야 한다.\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    # select_examples()\n",
    "    # 입력에 따라 어떠한 샘플을 사용할지 select 함.\n",
    "    \n",
    "    # 이번 예제에서는 examples 리스트 에서 random 으로 선택하게 하려 함.\n",
    "    # ※ 이는 얼마든지 복잡하게 만들어 볼수도 있다.\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]  # examples 에서 무작위로 1개 선택\n",
    "    \n",
    "    \n",
    "    # add_example()\n",
    "    # Add new example to store.  이미 존재하는 example 에 example 을 추가하는 method\n",
    "    def add_example(self,example):\n",
    "        self.examples.append(example)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a9c61d01-fa27-4024-82a3-dc84b853a9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Greece\n",
      "AI: \n",
      "      I know this:\n",
      "      Capital: Athens\n",
      "      Language: Greek\n",
      "      Food: Souvlaki and Feta Cheese\n",
      "      Currency: Euro\n",
      "      \n",
      "\n",
      "Human: What do you know about Brazil\n"
     ]
    }
   ],
   "source": [
    "example_selector = RandomExampleSelector(examples=examples)\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,  # 커스텀 ExampleSelector !\n",
    "\n",
    "    suffix=\"Human: What do you know about {country}\",\n",
    "    input_variables = ['country'],\n",
    ")\n",
    "\n",
    "print(prompt.format(country='Brazil'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966ac614-cbf0-456a-8560-33bb6d132303",
   "metadata": {},
   "source": [
    "# 4.PromptTemplate 저장/읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957dc8e2-0ade-4e11-8ab6-348d396ead57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 를 파일로 다룰 경우\n",
    "#   'JSON' 파일  혹은 'YAML' 파일 로 만들수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6a1212-c1ee-417c-8bbc-766f94aa9643",
   "metadata": {},
   "source": [
    "## json 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "05220f69-19b0-44fc-9b8d-1056a8f0c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompt.json', 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "    {\n",
    "      \"_type\": \"prompt\",\n",
    "      \"template\": \"What is the capital of {country}\",\n",
    "      \"input_variables\": [\"country\"]\n",
    "    }\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e5992730-37da-4c1d-b156-3ccd2502c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts.loading import load_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "34638aed-e67e-43dd-b16b-c9f44406514e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " D 드라이브의 볼륨: 새 볼륨\n",
      " 볼륨 일련 번호: 02B1-19A2\n",
      "\n",
      " D:\\NLP2507\\LangWork\\LangChain기초 디렉터리\n",
      "\n",
      "2025-12-04  오후 09:10               139 prompt.json\n",
      "               1개 파일                 139 바이트\n",
      "               0개 디렉터리  451,150,381,056 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir *.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "49f4d746-7e61-432f-b7d9-8b8068e587e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = load_prompt('./prompt.json')  # PromptTemplate 객체 리턴\n",
    "\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1ecb7ef0-7890-445f-9de9-b3b5fa1fe641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Canada'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(country='Canada')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc330050-375f-4954-b028-1e8fab68142c",
   "metadata": {},
   "source": [
    "## yaml 파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd06253-6d20-465a-b1e3-e2da5f31a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt.yaml 파일을 만든다\n",
    "\n",
    "# name: value\n",
    "#  ★ name 은 쌍따옴표 없다.  : 다음에 한칸 꼭 띄우기!   뒤에 콤마 없다\n",
    "\"\"\"\n",
    "_type: \"prompt\"\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8de6d884-9311-40fc-ba82-1e249a1c5014",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompt.yaml', 'w') as f:\n",
    "    f.write(\"\"\"\n",
    "_type: \"prompt\"\n",
    "template: \"What is the capital of {country}\"\n",
    "input_variables: [\"country\"]\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2ff2f113-6c1c-45ff-91b3-0cbe062ccf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_type: \"prompt\"\n",
      "template: \"What is the capital of {country}\"\n",
      "input_variables: [\"country\"]\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "!type prompt.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d4abd44b-d61b-4323-8086-f2ff3e47150f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['country'] input_types={} partial_variables={} template='What is the capital of {country}'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'What is the capital of England'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = load_prompt('./prompt.yaml')\n",
    "print(prompt)\n",
    "\n",
    "prompt.format(country='England')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc95108f-eb29-4ef5-b927-bf9f02e3baea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958a5bba-febf-4d03-bba4-636386b30574",
   "metadata": {},
   "source": [
    "# Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "42bb28ae-5253-4efb-83f3-66c0cfd32834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching 을 사용하면 모델의 응답을 저장할수 있다.\n",
    "# 예를들어\n",
    "# 똑같은 질문을 받는 상황이라면 그 때마다 답변생성할 필요 없이\n",
    "# 이미 캐싱된 답변을 재사용 할수 있는 것이다 -->  비용절감! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f420a133-3694-49f0-9c5c-10644a74b0b7",
   "metadata": {},
   "source": [
    "## set_llm_cache(), InMemoryCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "61fb1b2e-4243-4352-9c5c-4d666617d2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_core.caches import InMemoryCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ee973a7d-4f50-4d6a-b3e9-18696e6ae6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_llm_cache(InMemoryCache())  # LLM 의 모든 response 는 '메모리' 에 cache 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a66fcd17-1dc0-48cd-b7a6-036d97a55380",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2ef745ca-3f5b-4a1d-8151-e55d71087668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동일한 질문을 여러번 해볼거다.  시간 측정하는 함수 준비\n",
    "import time\n",
    "from datetime import timedelta\n",
    "\n",
    "def check_laptime(message):\n",
    "    start_time = time.time()\n",
    "    response = chat.invoke(message)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time # 경과시간\n",
    "    print('▶ 경과시간 %s' % (str(timedelta(seconds = elapsed_time))))\n",
    "    print(f'{len(response.content)} 글자: {response.content}\\n')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b326d4d6-c3d4-415b-8581-964d3ee6a516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ 경과시간 0:00:05.675641\n",
      "1805 글자: To make authentic Italian pizza, you will need the following ingredients:\n",
      "\n",
      "- 2 1/4 cups of all-purpose flour\n",
      "- 1 teaspoon of salt\n",
      "- 1 teaspoon of sugar\n",
      "- 1 packet of active dry yeast\n",
      "- 1 cup of warm water\n",
      "- 2 tablespoons of olive oil\n",
      "- Tomato sauce\n",
      "- Fresh mozzarella cheese\n",
      "- Fresh basil leaves\n",
      "- Any additional toppings of your choice (such as pepperoni, mushrooms, or olives)\n",
      "\n",
      "Here is a step-by-step guide to making Italian pizza:\n",
      "\n",
      "1. In a large mixing bowl, combine the flour, salt, and sugar. In a separate small bowl, dissolve the yeast in the warm water and let it sit for about 5 minutes until it becomes frothy.\n",
      "\n",
      "2. Pour the yeast mixture and olive oil into the flour mixture and stir until a dough forms. Knead the dough on a floured surface for about 5-7 minutes until it becomes smooth and elastic.\n",
      "\n",
      "3. Place the dough in a greased bowl, cover it with a clean towel, and let it rise in a warm place for about 1-2 hours until it doubles in size.\n",
      "\n",
      "4. Preheat your oven to the highest temperature setting (usually around 500°F or higher) and place a pizza stone or baking sheet in the oven to heat up.\n",
      "\n",
      "5. Punch down the dough and divide it into two equal portions. Roll out each portion into a round shape on a floured surface, making sure it is thin and even.\n",
      "\n",
      "6. Place the rolled-out dough on a piece of parchment paper and top it with tomato sauce, fresh mozzarella cheese, and any additional toppings of your choice.\n",
      "\n",
      "7. Carefully transfer the pizza (with the parchment paper) onto the preheated pizza stone or baking sheet in the oven. Bake for about 10-12 minutes until the crust is golden brown and the cheese is melted and bubbly.\n",
      "\n",
      "8. Remove the pizza from the oven, top it with fresh basil leaves, and let it cool slightly before slicing and serving.\n",
      "\n",
      "Enjoy your homemade Italian pizza!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_laptime(\"How do you make Italian pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3fbb9f16-ed69-42b3-bb51-1992005551e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ 경과시간 0:00:00\n",
      "1805 글자: To make authentic Italian pizza, you will need the following ingredients:\n",
      "\n",
      "- 2 1/4 cups of all-purpose flour\n",
      "- 1 teaspoon of salt\n",
      "- 1 teaspoon of sugar\n",
      "- 1 packet of active dry yeast\n",
      "- 1 cup of warm water\n",
      "- 2 tablespoons of olive oil\n",
      "- Tomato sauce\n",
      "- Fresh mozzarella cheese\n",
      "- Fresh basil leaves\n",
      "- Any additional toppings of your choice (such as pepperoni, mushrooms, or olives)\n",
      "\n",
      "Here is a step-by-step guide to making Italian pizza:\n",
      "\n",
      "1. In a large mixing bowl, combine the flour, salt, and sugar. In a separate small bowl, dissolve the yeast in the warm water and let it sit for about 5 minutes until it becomes frothy.\n",
      "\n",
      "2. Pour the yeast mixture and olive oil into the flour mixture and stir until a dough forms. Knead the dough on a floured surface for about 5-7 minutes until it becomes smooth and elastic.\n",
      "\n",
      "3. Place the dough in a greased bowl, cover it with a clean towel, and let it rise in a warm place for about 1-2 hours until it doubles in size.\n",
      "\n",
      "4. Preheat your oven to the highest temperature setting (usually around 500°F or higher) and place a pizza stone or baking sheet in the oven to heat up.\n",
      "\n",
      "5. Punch down the dough and divide it into two equal portions. Roll out each portion into a round shape on a floured surface, making sure it is thin and even.\n",
      "\n",
      "6. Place the rolled-out dough on a piece of parchment paper and top it with tomato sauce, fresh mozzarella cheese, and any additional toppings of your choice.\n",
      "\n",
      "7. Carefully transfer the pizza (with the parchment paper) onto the preheated pizza stone or baking sheet in the oven. Bake for about 10-12 minutes until the crust is golden brown and the cheese is melted and bubbly.\n",
      "\n",
      "8. Remove the pizza from the oven, top it with fresh basil leaves, and let it cool slightly before slicing and serving.\n",
      "\n",
      "Enjoy your homemade Italian pizza!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_laptime(\"How do you make Italian pizza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccc7900-6eaa-49d6-9c6d-71b0f666c73c",
   "metadata": {},
   "source": [
    "## set_debug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1a022b51-a56a-439d-90db-ff38dfdc8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.globals import set_debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b6dbc0d6-efb0-41fd-b72d-fadcb6fc885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1dac8f70-56f4-49c1-8aaf-c15168d47587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make Korean Kimbab\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [4.05s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"To make Korean kimbap, you will need the following ingredients:\\n\\n- 4 cups cooked short grain rice\\n- 5-6 sheets of seaweed (nori)\\n- 1/2 lb of bulgogi (marinated beef) or other protein of your choice\\n- 1 carrot, julienned\\n- 1 cucumber, julienned\\n- 1/2 cup pickled radish, julienned\\n- 4 eggs, beaten and cooked into thin omelettes\\n- Sesame oil\\n- Salt\\n- Sugar\\n- Soy sauce\\n- Rice vinegar\\n\\nInstructions:\\n\\n1. Cook the rice according to package instructions and let it cool slightly.\\n2. Season the rice with a mixture of sesame oil, salt, and sugar to taste.\\n3. Lay a sheet of seaweed on a bamboo sushi mat or a clean kitchen towel.\\n4. Spread a thin layer of rice over the seaweed, leaving a small border at the top.\\n5. Arrange the bulgogi, carrot, cucumber, pickled radish, and egg omelette in a line across the rice.\\n6. Roll the kimbap tightly using the sushi mat or towel, pressing gently to seal.\\n7. Cut the kimbap into bite-sized pieces using a sharp knife.\\n8. Serve with soy sauce mixed with a little rice vinegar for dipping.\\n\\nEnjoy your homemade Korean kimbap!\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 291,\n",
      "                \"prompt_tokens\": 14,\n",
      "                \"total_tokens\": 305,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"id\": \"chatcmpl-Cj2kawivrBZ518mTS7pqqmC64CK7g\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--2ab3ea5a-c260-4dc1-8a1a-27448cd7a227-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 14,\n",
      "              \"output_tokens\": 291,\n",
      "              \"total_tokens\": 305,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        },\n",
      "        \"text\": \"To make Korean kimbap, you will need the following ingredients:\\n\\n- 4 cups cooked short grain rice\\n- 5-6 sheets of seaweed (nori)\\n- 1/2 lb of bulgogi (marinated beef) or other protein of your choice\\n- 1 carrot, julienned\\n- 1 cucumber, julienned\\n- 1/2 cup pickled radish, julienned\\n- 4 eggs, beaten and cooked into thin omelettes\\n- Sesame oil\\n- Salt\\n- Sugar\\n- Soy sauce\\n- Rice vinegar\\n\\nInstructions:\\n\\n1. Cook the rice according to package instructions and let it cool slightly.\\n2. Season the rice with a mixture of sesame oil, salt, and sugar to taste.\\n3. Lay a sheet of seaweed on a bamboo sushi mat or a clean kitchen towel.\\n4. Spread a thin layer of rice over the seaweed, leaving a small border at the top.\\n5. Arrange the bulgogi, carrot, cucumber, pickled radish, and egg omelette in a line across the rice.\\n6. Roll the kimbap tightly using the sushi mat or towel, pressing gently to seal.\\n7. Cut the kimbap into bite-sized pieces using a sharp knife.\\n8. Serve with soy sauce mixed with a little rice vinegar for dipping.\\n\\nEnjoy your homemade Korean kimbap!\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 291,\n",
      "      \"prompt_tokens\": 14,\n",
      "      \"total_tokens\": 305,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null,\n",
      "    \"id\": \"chatcmpl-Cj2kawivrBZ518mTS7pqqmC64CK7g\"\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='To make Korean kimbap, you will need the following ingredients:\\n\\n- 4 cups cooked short grain rice\\n- 5-6 sheets of seaweed (nori)\\n- 1/2 lb of bulgogi (marinated beef) or other protein of your choice\\n- 1 carrot, julienned\\n- 1 cucumber, julienned\\n- 1/2 cup pickled radish, julienned\\n- 4 eggs, beaten and cooked into thin omelettes\\n- Sesame oil\\n- Salt\\n- Sugar\\n- Soy sauce\\n- Rice vinegar\\n\\nInstructions:\\n\\n1. Cook the rice according to package instructions and let it cool slightly.\\n2. Season the rice with a mixture of sesame oil, salt, and sugar to taste.\\n3. Lay a sheet of seaweed on a bamboo sushi mat or a clean kitchen towel.\\n4. Spread a thin layer of rice over the seaweed, leaving a small border at the top.\\n5. Arrange the bulgogi, carrot, cucumber, pickled radish, and egg omelette in a line across the rice.\\n6. Roll the kimbap tightly using the sushi mat or towel, pressing gently to seal.\\n7. Cut the kimbap into bite-sized pieces using a sharp knife.\\n8. Serve with soy sauce mixed with a little rice vinegar for dipping.\\n\\nEnjoy your homemade Korean kimbap!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 291, 'prompt_tokens': 14, 'total_tokens': 305, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-Cj2kawivrBZ518mTS7pqqmC64CK7g', 'finish_reason': 'stop', 'logprobs': None}, id='run--2ab3ea5a-c260-4dc1-8a1a-27448cd7a227-0', usage_metadata={'input_tokens': 14, 'output_tokens': 291, 'total_tokens': 305, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(\"How do you make Korean Kimbab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "658ff09e-723c-4cfb-a3d2-f8638dd1321e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_debug(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f3447-8837-4759-a7da-566ed2266f26",
   "metadata": {},
   "source": [
    "## SQLiteCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "34306b3e-3419-4565-bb97-e28b8d55a212",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.cache import SQLiteCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "112bc47d-820c-472f-9482-496740ce948a",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_llm_cache(SQLiteCache('cache.db'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1e78f7f2-8f1a-465d-87aa-cb73d6da2c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " D 드라이브의 볼륨: 새 볼륨\n",
      " 볼륨 일련 번호: 02B1-19A2\n",
      "\n",
      " D:\\NLP2507\\LangWork\\LangChain기초 디렉터리\n",
      "\n",
      "2025-12-04  오후 09:34    <DIR>          .\n",
      "2025-12-04  오후 09:34    <DIR>          ..\n",
      "2025-12-04  오후 07:27    <DIR>          .ipynb_checkpoints\n",
      "2025-12-04  오후 07:26            68,830 01 Hello LangChain.ipynb\n",
      "2025-12-04  오후 09:33            60,202 02 PromptTemplate.ipynb\n",
      "2025-12-04  오후 09:34            32,768 cache.db\n",
      "2025-12-04  오후 09:10               139 prompt.json\n",
      "2025-12-04  오후 09:15                99 prompt.yaml\n",
      "               5개 파일             162,038 바이트\n",
      "               3개 디렉터리  451,150,323,712 바이트 남음\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a452d800-67f2-4128-91f0-cc6bb0770c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ 경과시간 0:00:03.396522\n",
      "1872 글자: To make an authentic Italian pizza, you will need the following ingredients:\n",
      "\n",
      "- 2 1/4 cups of all-purpose flour\n",
      "- 1 teaspoon of salt\n",
      "- 1 teaspoon of sugar\n",
      "- 1 packet of active dry yeast\n",
      "- 1 cup of warm water\n",
      "- 2 tablespoons of olive oil\n",
      "- Tomato sauce\n",
      "- Fresh mozzarella cheese\n",
      "- Fresh basil leaves\n",
      "- Any additional toppings of your choice (such as pepperoni, mushrooms, or olives)\n",
      "\n",
      "Here is a step-by-step guide to making Italian pizza:\n",
      "\n",
      "1. In a large mixing bowl, combine the flour, salt, and sugar. In a separate small bowl, dissolve the yeast in warm water and let it sit for about 5 minutes until it becomes frothy.\n",
      "\n",
      "2. Pour the yeast mixture and olive oil into the dry ingredients and mix until a dough forms. Knead the dough on a floured surface for about 5-7 minutes until it becomes smooth and elastic.\n",
      "\n",
      "3. Place the dough in a lightly oiled bowl, cover it with a clean towel, and let it rise in a warm place for about 1-2 hours until it doubles in size.\n",
      "\n",
      "4. Preheat your oven to the highest temperature setting (usually around 500°F or 260°C) and place a pizza stone or baking sheet in the oven to heat up.\n",
      "\n",
      "5. Once the dough has risen, punch it down and divide it into two equal portions. Roll out each portion into a round shape on a floured surface, making sure it is thin in the middle and slightly thicker around the edges.\n",
      "\n",
      "6. Place the rolled-out dough on a piece of parchment paper and top it with tomato sauce, fresh mozzarella cheese, and any additional toppings of your choice.\n",
      "\n",
      "7. Carefully transfer the pizza (with the parchment paper) onto the preheated pizza stone or baking sheet in the oven. Bake for about 10-12 minutes until the crust is golden brown and the cheese is melted and bubbly.\n",
      "\n",
      "8. Remove the pizza from the oven, top it with fresh basil leaves, and let it cool slightly before slicing and serving.\n",
      "\n",
      "Enjoy your homemade Italian pizza!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_laptime(\"How do you make Italian pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "74efc143-15f3-448e-8b68-771f34c52aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ 경과시간 0:00:00.001995\n",
      "1872 글자: To make an authentic Italian pizza, you will need the following ingredients:\n",
      "\n",
      "- 2 1/4 cups of all-purpose flour\n",
      "- 1 teaspoon of salt\n",
      "- 1 teaspoon of sugar\n",
      "- 1 packet of active dry yeast\n",
      "- 1 cup of warm water\n",
      "- 2 tablespoons of olive oil\n",
      "- Tomato sauce\n",
      "- Fresh mozzarella cheese\n",
      "- Fresh basil leaves\n",
      "- Any additional toppings of your choice (such as pepperoni, mushrooms, or olives)\n",
      "\n",
      "Here is a step-by-step guide to making Italian pizza:\n",
      "\n",
      "1. In a large mixing bowl, combine the flour, salt, and sugar. In a separate small bowl, dissolve the yeast in warm water and let it sit for about 5 minutes until it becomes frothy.\n",
      "\n",
      "2. Pour the yeast mixture and olive oil into the dry ingredients and mix until a dough forms. Knead the dough on a floured surface for about 5-7 minutes until it becomes smooth and elastic.\n",
      "\n",
      "3. Place the dough in a lightly oiled bowl, cover it with a clean towel, and let it rise in a warm place for about 1-2 hours until it doubles in size.\n",
      "\n",
      "4. Preheat your oven to the highest temperature setting (usually around 500°F or 260°C) and place a pizza stone or baking sheet in the oven to heat up.\n",
      "\n",
      "5. Once the dough has risen, punch it down and divide it into two equal portions. Roll out each portion into a round shape on a floured surface, making sure it is thin in the middle and slightly thicker around the edges.\n",
      "\n",
      "6. Place the rolled-out dough on a piece of parchment paper and top it with tomato sauce, fresh mozzarella cheese, and any additional toppings of your choice.\n",
      "\n",
      "7. Carefully transfer the pizza (with the parchment paper) onto the preheated pizza stone or baking sheet in the oven. Bake for about 10-12 minutes until the crust is golden brown and the cheese is melted and bubbly.\n",
      "\n",
      "8. Remove the pizza from the oven, top it with fresh basil leaves, and let it cool slightly before slicing and serving.\n",
      "\n",
      "Enjoy your homemade Italian pizza!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check_laptime(\"How do you make Italian pizza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b50932-d7ea-4510-91c9-737bcaccd759",
   "metadata": {},
   "source": [
    "## debug, cache 사용 끄기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f3ebef2c-a83f-48ea-973f-1bc2eb57c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_debug(False)\n",
    "set_llm_cache(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5effbca1-6c52-45d1-a966-1427fded9ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58b009c3-c1f5-4892-b283-01505f23a463",
   "metadata": {},
   "source": [
    "# Model Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338f2b14-62c9-4eb6-8585-8e0b148f5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번 단원에서 두가지를 배워볼거다\n",
    "\n",
    "# 첫째:  OpanAI 의 모델을 사용할 때 우리가 지출하는 비용을 하는 방법\n",
    "# 둘째: 모델을 어떻게 저장하고(serialize) 불러오는지에 대한 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baff4d6f-329f-4e74-8c9f-c96df8248645",
   "metadata": {},
   "source": [
    "## OpenAI 모델 호출 비용 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e2b3d081-961a-4414-9936-4dd95e345873",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.callbacks.manager import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9ee8601c-753e-49e3-a950-fcfb56c4e50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟦 Tokens Used: 202\n",
      "\tPrompt Tokens: 14\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 188\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.00028900000000000003\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as usage:\n",
    "    chat.invoke(\"What is the recipe for soju\")\n",
    "    print('🟦', usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0cc8c093-6ce8-4000-a1e3-8971dba003a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤧 Ingredients:\n",
      "- 1 cup of rice\n",
      "- 1 cup of water\n",
      "- 1 tablespoon of yeast\n",
      "- 1 tablespoon of sugar\n",
      "\n",
      "Instructions:\n",
      "1. Rinse the rice thoroughly and soak it in water for at least 1 hour.\n",
      "2. Drain the rice and place it in a steamer basket. Steam the rice for about 30 minutes, or until it is cooked through.\n",
      "3. Allow the rice to cool to room temperature.\n",
      "4. In a large bowl, mix the yeast and sugar with the water until dissolved.\n",
      "5. Add the cooked rice to the yeast mixture and stir well.\n",
      "6. Cover the bowl with a clean cloth and let it sit at room temperature for 1-2 days, stirring occasionally.\n",
      "7. After 1-2 days, strain the mixture through a cheesecloth or fine mesh strainer to remove any solids.\n",
      "8. Transfer the liquid to a clean bottle or jar and store it in the refrigerator.\n",
      "9. Serve the homemade soju chilled and enjoy responsibly.\n",
      "\n",
      "🥶 Ingredients:\n",
      "- 4 cups cooked short-grain white rice\n",
      "- 5-6 sheets of seaweed (nori)\n",
      "- 1 carrot, julienned\n",
      "- 1 cucumber, julienned\n",
      "- 1/2 red bell pepper, julienned\n",
      "- 1/2 yellow bell pepper, julienned\n",
      "- 1/2 avocado, sliced\n",
      "- 1/2 lb cooked bulgogi beef or imitation crab sticks\n",
      "- 2 eggs, beaten\n",
      "- Salt and pepper to taste\n",
      "- Sesame oil\n",
      "- Sesame seeds\n",
      "\n",
      "For the dipping sauce:\n",
      "- 2 tbsp soy sauce\n",
      "- 1 tbsp rice vinegar\n",
      "- 1 tsp sugar\n",
      "- 1/2 tsp sesame oil\n",
      "- 1/2 tsp sesame seeds\n",
      "\n",
      "Instructions:\n",
      "1. In a small bowl, mix together the ingredients for the dipping sauce and set aside.\n",
      "2. Heat a non-stick skillet over medium heat and add a little bit of oil. Pour in the beaten eggs and swirl the pan to create a thin omelette. Cook until set, then flip and cook for another minute. Remove from heat and slice into thin strips.\n",
      "3. Place a sheet of seaweed on a bamboo sushi mat or a clean kitchen towel. Spread a thin layer of rice evenly over the seaweed, leaving a 1-inch border at the top.\n",
      "4. Arrange the julienned vegetables, avocado, bulgogi beef or crab sticks, and egg strips in a line across the center of the rice.\n",
      "5. Roll the kimbap tightly using the bamboo mat or towel, pressing gently to seal the edge. Repeat with the remaining ingredients.\n",
      "6. Brush the outside of the kimbap with a little bit of sesame oil and sprinkle with sesame seeds.\n",
      "7. Slice the kimbap into bite-sized pieces and serve with the dipping sauce. Enjoy!\n",
      "🟦 Tokens Used: 625\n",
      "\tPrompt Tokens: 29\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 596\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 2\n",
      "Total Cost (USD): $0.0009085\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as usage:\n",
    "    a = chat.invoke(\"What is the recipe for soju\")\n",
    "    b = chat.invoke(\"What is the recipe for kimbab\")\n",
    "    print('\\n🤧', a.content)\n",
    "    print('\\n🥶', b.content)\n",
    "    print('🟦', usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c3aa1-48ba-463b-b66d-fa4ae16b8f99",
   "metadata": {},
   "source": [
    "## 모델 config 저장하고 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5864b0f9-2f6f-44cb-a005-57b8749779d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\n",
    "    temperature=0.1,\n",
    "    max_tokens=450,  # !!\n",
    "    model=\"gpt-4-turbo\" # 사용 모델 설정\n",
    ")\n",
    "\n",
    "# 모델(config)을 저장하려면\n",
    "llm.save(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1e52559a-ec1a-4714-9585-cc7524ead0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"model_name\": \"gpt-4-turbo\",\n",
      "    \"temperature\": 0.1,\n",
      "    \"top_p\": 1,\n",
      "    \"frequency_penalty\": 0,\n",
      "    \"presence_penalty\": 0,\n",
      "    \"n\": 1,\n",
      "    \"seed\": null,\n",
      "    \"logprobs\": null,\n",
      "    \"max_tokens\": 450,\n",
      "    \"_type\": \"openai\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!type model.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3c88600b-cf56-4979-9086-1711b4b0ba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.loading import load_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a75c49c7-71b6-483a-a9ab-76d6c36c169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\NLP2507\\LangWork\\.venv\\Lib\\site-packages\\langchain_community\\llms\\openai.py:255: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "D:\\NLP2507\\LangWork\\.venv\\Lib\\site-packages\\langchain_community\\llms\\openai.py:1089: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain_community.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = load_llm('model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2197fb-a7c9-44c6-b828-a8ce955ed012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ed2fc5-212a-4c1b-a58b-441102c4c371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38a85a5-6ee8-44a6-a7b3-cf63e2a12bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8effec-eb81-4c49-97ab-fd0d7b87384a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57746075-ae10-4a44-8ecc-959ac99cbd54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864bac5-5673-4517-a8b7-a5bcfdc7e847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e035fb8-e92f-4fd5-a513-215fe9389f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241969fe-374d-4c16-8a8c-5f2b34e2f2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d4603-d879-44dc-92b0-7a679816c450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7662131-3450-4273-9033-4b909648293e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49c9bbd-dced-4556-8233-bec7a18c787f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e42961-453f-4c23-ba67-0c1a0da59548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e248bfa9-02c0-4929-9693-03e7ba9eedc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f7eca8-23fc-41a3-a194-071e5f42de99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91ea069-0a61-4928-99ca-cb068ccd6d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef3b37b-d9eb-4d41-aaaa-9cead97ec927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb7cbad-0233-4a97-ac77-39fc1c059db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1e4881-4ed1-42ae-933f-d28ce4c538a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e4ed6-2d16-418b-92ad-e655b8b2b4ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442036f3-bc3a-4cb0-b917-bb59666deac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb11e16b-ab52-4d52-926b-6618fead4a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0373711-3e25-4bc7-ac1d-9a06cddf9791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5862821-d1c1-41bd-b12e-902bedb34a96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a7df52-c00e-4141-a42c-aac80143365a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80d1ece-049a-4ddb-b7f7-757b4242d026",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a52750-8ca2-4924-a04c-862ffbd3db10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cdd7d0-a019-4f91-9ac1-cf9eff03d105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6601e901-ea71-4bf7-8b9c-8c6b1a753151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6be0e1-8874-4dee-94f9-f36c48883ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcac761-8331-4348-852f-0a2afb528957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b772a-4769-4aa7-b0e3-83ad90a35100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c78baa-2a74-4ef7-bf48-c1a7ec4ca3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0519e-0a64-41c2-a12f-b7dd34990625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64788f09-4fb7-4754-a1c3-9fa542429359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a128968d-2cd4-42ca-9acd-6e496621434b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128f3ed2-32f3-47bf-9d42-fed69b02b03d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6e85b3-70e3-448a-9221-fc7bda42f5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88278f8-24c2-4fa0-81c9-527dd741b141",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
