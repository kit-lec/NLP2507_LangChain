import os, time
from dotenv import load_dotenv

load_dotenv()  #

print(f'âœ… {os.path.basename( __file__ )} ì‹¤í–‰ë¨ {time.strftime('%Y-%m-%d %H:%M:%S')}')  # ì‹¤í–‰íŒŒì¼ëª…, í˜„ì¬ì‹œê°„ì¶œë ¥
print(f'\tOPENAI_API_KEY={os.getenv("OPENAI_API_KEY")[:20]}...') # OPENAI_API_KEY í•„ìš”!
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import streamlit as st
import glob
import subprocess
import math
from pydub import AudioSegment
import openai


from langchain_openai.chat_models.base import ChatOpenAI
from langchain_core.prompts.chat import ChatPromptTemplate
from langchain_community.document_loaders.text import TextLoader
from langchain_text_splitters.character import RecursiveCharacterTextSplitter
from langchain_core.output_parsers import StrOutputParser

from langchain_community.vectorstores.faiss import FAISS
from langchain.embeddings.cache import CacheBackedEmbeddings
from langchain_openai.embeddings.base import OpenAIEmbeddings
from langchain.storage.file_system import LocalFileStore


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸƒ LLM ë¡œì§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
llm = ChatOpenAI(
    temperature=0.1,
)



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ‡ file load & cache
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
file_dir = os.path.dirname(os.path.realpath(__file__)) # *.py íŒŒì¼ì˜ 'ê²½ë¡œ'ë§Œ
# .cache  â† ì—…ë¡œë“œí•œ ë¹„ë””ì˜¤ ì™€ ë³€í™˜í•œ mp3
# .cache/chunks â† ë¶„í• ëœ mp3 íŒŒì¼ë“¤ ì €ì¥
upload_dir = os.path.join(file_dir, '.cache/chunks')
if not os.path.exists(upload_dir):
    os.makedirs(upload_dir)

# ğŸ•â€ğŸ¦ºí•™ìŠµìš©: transcript í•œë²ˆí–ˆìœ¼ë©´ ì¤‘ë³µí•´ì„œ ì‹¤í–‰í•˜ì§€ ì•Šê¸°
has_transcript = os.path.exists(os.path.join(file_dir, r'.cache/podcast.txt'))

# ì˜¤ë””ì˜¤ ì¶”ì¶œí•¨ìˆ˜
# ì—…ë¡œë“œí•œ video(mp4)ì—ì„œ ì˜¤ë””ì˜¤(mp3) ì¶”ì¶œí•˜ì—¬ ë™ì¼ ê²½ë¡œì— ì €ì¥.
@st.cache_resource()
def extract_audio_from_video(video_path):  
    if has_transcript: return  # ğŸ•â€ğŸ¦ºí•™ìŠµìš©  
    audio_path = video_path.replace("mp4", "mp3")  
    command = [
        "ffmpeg",
        "-i",
        video_path,
        "-vn",
        audio_path,
        "-y",  # -y ì˜µì…˜ì´ ìˆì–´ì•¼ yes / no ë¬¼ì–´ë³¼ì‹œ yes ìë™ì„ íƒí•˜ê³  ë„˜ì–´ê°€ê²Œ ëœë‹¤.
        ]
    subprocess.run(command)    


# audio_path : ì›ë³¸ ì˜¤ë””ì˜¤ ê²½ë¡œ
# chunk_size : minute
# chunks_folder: chunk ë“¤ì„ ì €ì¥í•  í´ë”
@st.cache_resource()
def cut_audio_in_chunks(audio_path, chunk_size, chunks_folder):
    if has_transcript: return  # ğŸ•â€ğŸ¦ºí•™ìŠµìš©  
    track = AudioSegment.from_mp3(audio_path)
    chunk_len = chunk_size * 60 * 1000
    chunks = math.ceil(len(track) / chunk_len)
    for i in range(chunks):
        start_time = i * chunk_len
        end_time = (i + 1) * chunk_len

        chunk = track[start_time:end_time]

        exp_path = os.path.join(chunks_folder, f"chunk_{i}.mp3")
        chunk.export(exp_path, format="mp3")

# chunk_folder :
# destination : ë…¹ì·¨ë¡ì´ ë“¤ì–´ê°„ í…ìŠ¤íŠ¸ íŒŒì¼ì´ ì €ì¥ë  ë””ë ‰í† ë¦¬
@st.cache_resource()
def transcribe_chunks(chunk_folder, destination):
    if has_transcript: return  # ğŸ•â€ğŸ¦ºí•™ìŠµìš©  
    files = glob.glob(os.path.join(chunk_folder, "chunk*.mp3"))
    files.sort()
    for file in files:
        with open(file, "rb") as audio_file, open(destination, "a") as text_file:# append mode
            print(file, 'ë…¹ì·¨ë¡ ê°€ì ¸ì˜¤ëŠ”ì¤‘...', end='')
            # ê° chunk ë³„ë¡œ ë…¹ì·¨ë¡ ì‘ì„±.
            transcript = openai.audio.transcriptions.create(
                model="whisper-1",
                file=audio_file,
                language="en"
            )
           
            text_file.write(transcript.text) # ê³§ë°”ë¡œ í…ìŠ¤íŠ¸ íŒŒì¼ì— ì €ì¥



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â­• Streamlit ë¡œì§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="MeetingGPT",
    page_icon="ğŸ¤",
)
st.markdown(
    """
# MeetingGPT
            
Welcome to MeetingGPT, upload a video and I will give you a transcript, a summary and a chat bot to ask any questions about it.

Get started by uploading a video file in the sidebar.
"""
)

with st.sidebar:
    video = st.file_uploader(
        label="Video",
        type=["mp4", "avi", "mkv", "mov"],
    )

if video:
    with st.status("Loading video...") as status:
        video_content = video.read()
        video_path = os.path.join(file_dir, rf".cache/{video.name}")
        audio_path = video_path.replace("mp4", "mp3")
        with open(video_path, 'wb') as f:
            f.write(video_content)

        # ë¹„ë””ì˜¤ -> ì˜¤ë””ì˜¤ ì¶”ì¶œ
        status.update(label="Extracting audio...")
        extract_audio_from_video(video_path)

        # ì˜¤ë””ì˜¤ ì˜ë¼ë‚´ê¸°
        status.update(label="Cutting audio segments...")
        chunks_folder = os.path.join(file_dir, r'./.cache/chunks')
        cut_audio_in_chunks(audio_path, 10, chunks_folder)

        # ë…¹ì·¨ë¡ íŒŒì¼ ìƒì„±
        status.update(label="Transcripting Audio...")
        transcript_path = video_path.replace("mp4", "txt")
        transcribe_chunks(chunks_folder, transcript_path)

