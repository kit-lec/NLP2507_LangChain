import os
import time
from dotenv import load_dotenv

load_dotenv()

print(f'âœ… {os.path.basename( __file__ )} ì‹¤í–‰ë¨ {time.strftime('%Y-%m-%d %H:%M:%S')}')  # ì‹¤í–‰íŒŒì¼ëª…, í˜„ì¬ì‹œê°„ì¶œë ¥
print(f'\tOPENAI_API_KEY={os.getenv("OPENAI_API_KEY")[:20]}...') # OPENAI_API_KEY í•„ìš”!
#â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

import streamlit as st

from langchain_community.document_loaders.unstructured import UnstructuredFileLoader
from langchain_text_splitters.character import CharacterTextSplitter

from langchain_openai.chat_models.base import ChatOpenAI
from langchain_core.prompts.chat import ChatPromptTemplate
from langchain_core.callbacks.streaming_stdout import StreamingStdOutCallbackHandler

from langchain_community.retrievers.wikipedia import WikipediaRetriever

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸƒ LLM ë¡œì§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€



# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ğŸ‡ file load & cache
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

file_dir = os.path.dirname(os.path.realpath(__file__)) # *.py íŒŒì¼ì˜ 'ê²½ë¡œ'ë§Œ
upload_dir = os.path.join(file_dir, '.cache/quiz_files')
if not os.path.exists(upload_dir):
    os.makedirs(upload_dir)

# split_file()
# vector, embedding í•„ìš”ì—†ë‹¤. ì˜¤ë¡œì§€ ë¬¸ì„œê°€ í•„ìš”í•˜ê³ ,
# ê·¸ ë¬¸ì„œë“¤ì„ split ê¹Œì§€ë§Œ í•´ë‘ë©´ ëœë‹¤.
@st.cache_resource(show_spinner="Loading file...")  # â† ì´ split_file() í•¨ìˆ˜ë¥¼ embed ë˜ì§„ ì•Šê³  caching ë§Œ ë ê±°ë‹¤.
def split_file(file):  # â†í•¨ìˆ˜ëª… ë³€ê²½
    file_content = file.read()
    file_path = os.path.join(upload_dir, file.name)
   
    with open(file_path, "wb") as f:
        f.write(file_content)

    splitter = CharacterTextSplitter.from_tiktoken_encoder(
        separator="\n",
        chunk_size=600,
        chunk_overlap=100,
    )

    loader = UnstructuredFileLoader(file_path)

    docs = loader.load_and_split(text_splitter=splitter)
    # â€» DocumentGPT ì— ìˆì—ˆë˜ ì´í•˜ embeddings ë‚˜ vectorstore ë“±ì„ í•„ìš”ì—†ë‹¤.
    #     embed í•˜ì§€ ì•Šì„ê±°ê³  ì–´ë–¤ ê²€ìƒ‰ë„ í•˜ì§€ ì•Šì„ê±°ë‹¤.
    #     ë‹¨ì§€ 'text file' ì„ ë„£ì–´ì¤„ê±°ê³ ,  ê·¸ ë¬¸ì„œë“¤ë¡œë¶€í„° quiz ë¥¼ ë§Œë“¤ê±°ë‹¤.
    return docs  # split í•œ List[Document] ë¦¬í„´!


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â­• Streamlit ë¡œì§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="QuizGPT",
    page_icon="ğŸ‘©â€ğŸš’",
)

st.title("QuizGPT")

with st.sidebar:

    docs = None  # ì½ì–´ë“¤ì¸ ë¬¸ì„œë“¤ List[Document]

    choice = st.selectbox(
        label="Choose what you want to use.",
        options=(
            "File",
            "Wikipedia Article",
        ),
    )

    if choice == "File":
        file = st.file_uploader(
            "Upload a .docx , .txt or .pdf file",
            type=["pdf", "txt", "docx"],            
        )
        # íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬ êµ¬í˜„
        if file:
            docs = split_file(file)
            st.write(len(docs), 'ê°œì˜ Document ë¡œ split')
            st.write(docs) # í™•ì¸ìš©

    else:
        topic = st.text_input("Search Wikipedia...")
        # Wikipedia Retriever ì‚¬ìš©
        if topic:
            # top_k_results=1 : retieve ê²°ê³¼ì¤‘ ì²«ë²ˆì§¸ ë¬¸ì„œë§Œ!
            retriever = WikipediaRetriever(top_k_results=5)

            with st.status("Searching Wikipedia..."):
                docs = retriever.invoke(topic)
                st.write(len(docs), 'ê°œì˜ ë¬¸ì„œ retrieve') # í™•ì¸ìš©
                st.write(docs)




























