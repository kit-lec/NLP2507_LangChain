{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyPVM6xSHspg/9yWhglxAq9p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a3947d20b3184e34a0555e06680755f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_61785581fc08479ba57c6a6e682bb0fe","IPY_MODEL_8b12b6ce26424f55b85a36cb148db758","IPY_MODEL_a9a0c8d330ea44ec8864fe8e407f7fda"],"layout":"IPY_MODEL_9351bc69e6724e58b52ceae636235718"}},"61785581fc08479ba57c6a6e682bb0fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f7f0588662149e0b308fafc75815485","placeholder":"​","style":"IPY_MODEL_955644ed0a76403392199674631360f6","value":"config.json: "}},"8b12b6ce26424f55b85a36cb148db758":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d1b4904f58c4218803c241e80b72799","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69dde5da482a4c52bac676a6422a0642","value":1}},"a9a0c8d330ea44ec8864fe8e407f7fda":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_94a764aec89d49b4bc2e4135e686a0a0","placeholder":"​","style":"IPY_MODEL_6996faf8151a4cd292d14f3aca820cae","value":" 1.00k/? [00:00&lt;00:00, 98.2kB/s]"}},"9351bc69e6724e58b52ceae636235718":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3f7f0588662149e0b308fafc75815485":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"955644ed0a76403392199674631360f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d1b4904f58c4218803c241e80b72799":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"69dde5da482a4c52bac676a6422a0642":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"94a764aec89d49b4bc2e4135e686a0a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6996faf8151a4cd292d14f3aca820cae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1046a31ad12c45c69be7a51ea3e6ff7a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_53f30f2b92804c83b8a5253780da2b32","IPY_MODEL_f90725b2da58448abfa831046547cb9e","IPY_MODEL_40ac892c06ce4f048f1529143efab8a2"],"layout":"IPY_MODEL_a162401e70854047bd7e53b79a3c0469"}},"53f30f2b92804c83b8a5253780da2b32":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d58a8b8d9d814c40ab6c27fa8880d22d","placeholder":"​","style":"IPY_MODEL_93000a66b13549b6b80dd5e4b66f0b03","value":"pytorch_model.bin: 100%"}},"f90725b2da58448abfa831046547cb9e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_75cb10fbc96e4dcc9d2cef2669f2bd19","max":513302779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f199c7284a6945dbbb526aaa797b8386","value":513302779}},"40ac892c06ce4f048f1529143efab8a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a25819231e6d4e659c45170f45816642","placeholder":"​","style":"IPY_MODEL_42f6c234f2144a2e85685f39acdb1ed9","value":" 513M/513M [00:05&lt;00:00, 88.8MB/s]"}},"a162401e70854047bd7e53b79a3c0469":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d58a8b8d9d814c40ab6c27fa8880d22d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93000a66b13549b6b80dd5e4b66f0b03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"75cb10fbc96e4dcc9d2cef2669f2bd19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f199c7284a6945dbbb526aaa797b8386":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a25819231e6d4e659c45170f45816642":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"42f6c234f2144a2e85685f39acdb1ed9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b61ec791c5b6467bbc22d72dbd2e4dae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec75277d6f5649b0b13f6318762d014e","IPY_MODEL_18efd8f3bb2a48f6a706444233f76b6b","IPY_MODEL_21028540a5db48da9a3b5d303865e5dc"],"layout":"IPY_MODEL_b5b245fc06fd416185b2dbc1621d5048"}},"ec75277d6f5649b0b13f6318762d014e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7ca5ae017254b9ab74be4f093e779a5","placeholder":"​","style":"IPY_MODEL_930a3d1df29f429fb0b8cee554bfdfc9","value":"tokenizer.json: "}},"18efd8f3bb2a48f6a706444233f76b6b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1778b9f5ff3c4a5f8b629adf28678339","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_12492a65c3a4478891478f8f70fb63af","value":1}},"21028540a5db48da9a3b5d303865e5dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d71b863b11944e995c54e9f12140df7","placeholder":"​","style":"IPY_MODEL_a0475e03de5f498c849581dee6e15c86","value":" 2.83M/? [00:00&lt;00:00, 97.2MB/s]"}},"b5b245fc06fd416185b2dbc1621d5048":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7ca5ae017254b9ab74be4f093e779a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"930a3d1df29f429fb0b8cee554bfdfc9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1778b9f5ff3c4a5f8b629adf28678339":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"12492a65c3a4478891478f8f70fb63af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d71b863b11944e995c54e9f12140df7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0475e03de5f498c849581dee6e15c86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a82260ade0248db8f123070594f5456":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5d85e696327048d5bf681ddd1e66548a","IPY_MODEL_d271c42d4f1c4a2a9b6e3e9c13c115b1","IPY_MODEL_21ab36aa62b34b9c928c42a52d828bce"],"layout":"IPY_MODEL_329c988ebbda40c1b59945f58836b932"}},"5d85e696327048d5bf681ddd1e66548a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5839b4a4244544b0982232b463e14f98","placeholder":"​","style":"IPY_MODEL_15c322047292425898a21854370a9905","value":" 87%"}},"d271c42d4f1c4a2a9b6e3e9c13c115b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_5450083b1bf94925ba8f653131078f8d","max":370,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3419f53a9eb54de6851fcc9a971ee5b4","value":322}},"21ab36aa62b34b9c928c42a52d828bce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ba64c89ba4a4f66824bfd52cc548eb6","placeholder":"​","style":"IPY_MODEL_27d6658e52ed44b099c208872357bd7e","value":" 322/370 [04:29&lt;00:36,  1.31it/s]"}},"329c988ebbda40c1b59945f58836b932":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5839b4a4244544b0982232b463e14f98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15c322047292425898a21854370a9905":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5450083b1bf94925ba8f653131078f8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3419f53a9eb54de6851fcc9a971ee5b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7ba64c89ba4a4f66824bfd52cc548eb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27d6658e52ed44b099c208872357bd7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["#  GPT(Generative Pre-trained Transformer)"],"metadata":{"id":"O5Hjh_26Blkj"}},{"cell_type":"markdown","source":["## 1. ChatGPT의 역사\n","\n","![](https://wikidocs.net/images/page/184363/gpt0.PNG)\n","\n","- BERT가 트랜스포머의 '인코더'로 설계된 모델이라면,\n","- GPT는 트랜스포머의 '디코더'로 설계된 모델.\n","\n","- Open AI는 2019년에 GPT-1을 공개한 이후로,\n","- 2019년 GPT-2, 2020년 GPT-3, 2022년 ChatGPT(GPT 3.5), 2023년에는 GPT-4, 2024년에는 GPT-4o를 공개하며 GPT 시리즈를 발전시켜 왔습니다.\n","\n","\n","\n","| &nbsp;       | GPT-1     | GPT-2 | GPT-3  | GPT-3.5 | GPT-4 Models |\n","|--------------|-----------|-------|--------|---------|--------------|\n","| 파라미터 개수      | 1억 1700만개 | 15억   | 1,750억 | ?       | 1조 8천억(추정)   |\n","| 디코더의 층       | 12        | 48    | 96     | ?       | ?            |\n","| 처리 가능한 토큰 개수 | 512       | 1024  | 2048   | ?       | 128,000      |\n","| 은닉층의 크기      | 768       | 1600  | 12288  | ?       | ?            |\n"],"metadata":{"id":"_PH_r55IEplX"}},{"cell_type":"markdown","source":["## 2. 거대 언어 모델(Large Language Model)\n","\n","- 언어 모델(Language Model)은 인공 지능 분야에서 컴퓨터가 사람의 언어를 이해하고 생성할 수 있도록 하는 기술입니다.\n","\n","- 이 모델은 대규모의 텍스트 데이터를 통해, 이전 단어들로부터 다음 단어를 예측하는 방식으로 작동합니다.\n","\n","  - 예를 들어, \"아침에 일어나 창문을 열었더니\"라는 문장이 주어지면, 언어 모델은 가장 그럴 듯한 다음 단어들을 나열하여 \"바람이 상쾌하게 불어왔다\"와 같은 이어지는 문장을 예측하는 모델입니다.\n","\n","- 언어 모델의 대표적인 예로는 OpenAI의 GPT(Generative Pre-trained Transformer) 시리즈가 있습니다.\n","\n","- 많은 입문자들이 착각하는 내용은 언어 모델과 GPT는 동격의 개념이 아니라는 것입니다.\n","\n","- 기본적으로 언어 모델은 이전 단어들로부터 다음 단어를 예측하는 생성 모델이고, GPT는 수많은 언어 모델 중 하나입니다.\n","  - 예를 들어서 구글의 Gemini, 앤트로픽의 Claude, 네이버의 CLOVA X와 같은 모델들도 언어 모델 중 하나일 것입니다.\n","  \n","- 이 중 딥 러닝 언어 모델로서 **파라미터 개수가 충분히 큰 언어 모델**을 우리는 **거대 언어 모델(Large Language Model)**이라고 부릅니다."],"metadata":{"id":"OlJ5bV-sEpiO"}},{"cell_type":"markdown","source":["## 3. GPT의 아키텍처\n","\n","![](https://wikidocs.net/images/page/184363/gpt2.png)\n","\n","- 트랜스포머: (인코더-디코더) 구조\n","- BERT : 인코더-디코더 아키텍처에서 인코더만 분리한 모델\n","\n","- **GPT(디코더 Only)** : 기본적으로 트랜스포머 디코더로만 구성\n","\n","  - GPT는 기본적으로 BERT와는 달리 '이전 단어'들로부터 '다음 단어'를 예측하는 모델 이기 때문에,\n","\n","  - 다음 단어를 지속적으로 생성할 수 있어 기본적으로 '글쓰기'가 가능한 '생성 모델'입니다.\n","\n","  - 트랜스포머 디코더 아키텍처를 가지며 다음 단어를 생성하는 이러한 구조는 현재 대부분의 거대 언어 모델이 채택하고 있는 구조이기도 합니다.\n","\n"],"metadata":{"id":"TwPzxqOfEpev"}},{"cell_type":"markdown","source":["**[↓그림: GPT-2 아키텍처]**\n","\n","![](https://wikidocs.net/images/page/184363/gpt3.PNG)\n","\n","- 위의 GPT-2 아키텍처를 도식화한 그림은 트랜스포머 디코더 층이 이전에 배웠던 초기 트랜스포머 디코더 층과 크게 다르지 않음을 보여줍니다.\n","\n","- 이전에 배웠던 트랜스포머에서의 디코더는 인코더가 같이 존재하는 아키텍처였기 때문에 인코더-디코더 어텐션이 존재했는데 여기서는 해당 부분이 제거되었습니다."],"metadata":{"id":"4ZOpSZaaEpbT"}},{"cell_type":"markdown","source":["**[GPT-1, GPT-2, GPT-3 아키텍쳐 비교]**\n","\n","![](https://wikidocs.net/images/page/184363/gpt.PNG)\n","\n","- 사실 GPT-1, GPT-2, GPT-3는 아키텍처 상으로는 큰 차이를 보이지 않습니다.\n","\n","1. GPT-1\n","  - 예컨대, GPT-1은 초기 트랜스포머 디코더에서 인코더-디코더 어텐션이 제거된 아키텍처이고,\n","\n","1. GPT-2\n","  - GPT-1에서는 층 정규화(Layer Normalization)가 서브층(Sub layer) 다음에 위치한다면, GPT-2는 서브층(Sub layer)의 입력으로 이동되었습니다.\n","\n","  - 그 외에는 초기화 방법이나, 단어 집합의 크기, 토큰 길이의 확장(GPT-1이 512였으나 GPT-2에서 1024로 증가) 정도의 차이를 가집니다.\n","\n","1. GPT-3\n","  - 이는 GPT-2에서 GPT-3로 모델이 다시 한 번 변경되었을 때에도 마찬가지입니다. OpenAI는 GPT-3에서도 특별히 새로운 모델, 아키텍처, 알고리즘을 제안하지 않습니다.\n","  - 그저 모델이 거대 언어 모델(Large Language Model)이 되면서 새로운 능력들이 발현되기 시작했다는 점이 뚜렷하게 볼 수 있는 차이점입니다."],"metadata":{"id":"tWawePafEpYD"}},{"cell_type":"markdown","source":["# GPT-2 를 이용한 문장 생성"],"metadata":{"id":"EgelFe0WEpTy"}},{"cell_type":"code","source":["# 한국어로 사전학습된 GPT-2 사용하여, 다음 문장 예측.\n","#  KoGPT-2"],"metadata":{"id":"HZE2G_jdBlh0","executionInfo":{"status":"ok","timestamp":1763727506762,"user_tz":-540,"elapsed":8,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import random\n","import tensorflow as tf\n","from transformers import AutoTokenizer # 특정모델에 알맞은 tokenizer 를 자동으로 불러오는 유틸리티 클래스\n","from transformers import TFGPT2LMHeadModel"],"metadata":{"id":"ZCTMBmvsBlfa","executionInfo":{"status":"ok","timestamp":1763727530915,"user_tz":-540,"elapsed":24151,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["model = TFGPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2', from_pt=True)\n","tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":351,"referenced_widgets":["a3947d20b3184e34a0555e06680755f5","61785581fc08479ba57c6a6e682bb0fe","8b12b6ce26424f55b85a36cb148db758","a9a0c8d330ea44ec8864fe8e407f7fda","9351bc69e6724e58b52ceae636235718","3f7f0588662149e0b308fafc75815485","955644ed0a76403392199674631360f6","1d1b4904f58c4218803c241e80b72799","69dde5da482a4c52bac676a6422a0642","94a764aec89d49b4bc2e4135e686a0a0","6996faf8151a4cd292d14f3aca820cae","1046a31ad12c45c69be7a51ea3e6ff7a","53f30f2b92804c83b8a5253780da2b32","f90725b2da58448abfa831046547cb9e","40ac892c06ce4f048f1529143efab8a2","a162401e70854047bd7e53b79a3c0469","d58a8b8d9d814c40ab6c27fa8880d22d","93000a66b13549b6b80dd5e4b66f0b03","75cb10fbc96e4dcc9d2cef2669f2bd19","f199c7284a6945dbbb526aaa797b8386","a25819231e6d4e659c45170f45816642","42f6c234f2144a2e85685f39acdb1ed9","b61ec791c5b6467bbc22d72dbd2e4dae","ec75277d6f5649b0b13f6318762d014e","18efd8f3bb2a48f6a706444233f76b6b","21028540a5db48da9a3b5d303865e5dc","b5b245fc06fd416185b2dbc1621d5048","e7ca5ae017254b9ab74be4f093e779a5","930a3d1df29f429fb0b8cee554bfdfc9","1778b9f5ff3c4a5f8b629adf28678339","12492a65c3a4478891478f8f70fb63af","7d71b863b11944e995c54e9f12140df7","a0475e03de5f498c849581dee6e15c86"]},"id":"roXdtvoyIHtx","executionInfo":{"status":"ok","timestamp":1763727544067,"user_tz":-540,"elapsed":13150,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"834a910b-0b42-4a64-daa5-f598ea8e49a0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3947d20b3184e34a0555e06680755f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1046a31ad12c45c69be7a51ea3e6ff7a"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n","Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.9.attn.masked_bias', 'lm_head.weight', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.10.attn.masked_bias']\n","- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b61ec791c5b6467bbc22d72dbd2e4dae"}},"metadata":{}}]},{"cell_type":"code","source":["sent = \"근육이 커지기 위해서는\""],"metadata":{"id":"8C3CUACKIwhf","executionInfo":{"status":"ok","timestamp":1763727544070,"user_tz":-540,"elapsed":2,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["input_ids = tokenizer.encode(sent)\n","input_ids = tf.convert_to_tensor([input_ids])\n","\n","input_ids"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZGdV6D1HBlcp","executionInfo":{"status":"ok","timestamp":1763727544086,"user_tz":-540,"elapsed":14,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"3e501be7-ba13-440b-e577-a54a4d55a217"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 4), dtype=int32, numpy=array([[33245, 10114, 12748, 11357]], dtype=int32)>"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["output = model.generate(input_ids,\n","               max_length=128,\n","               repetition_penalty=2.0,  # 텍스트 생성 같은 단어나 토큰이 과도하게 반복되는 것을 방지하기 위한 파라미터\n","               use_cache=True)\n","\n","output"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Wm8BBFiBlZ7","executionInfo":{"status":"ok","timestamp":1763727570494,"user_tz":-540,"elapsed":26406,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"09610019-2ff2-4755-8681-678779efa11e"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n","array([[33245, 10114, 12748, 11357, 23879, 39306,  9684,  7884, 10211,\n","        15177, 26421,   387, 17339,  7889,  9908, 15768,  6903, 15386,\n","         8146, 12923,  9228, 18651, 42600,  9564, 17764,  9033,  9199,\n","        14441,  7335,  8704, 12557, 32030,  9510, 18595,  9025, 10571,\n","        25741, 10599, 13229,  9508,  7965,  8425, 33102,  9122, 21240,\n","         9801, 32106, 13579, 12442, 13235, 19430,  8022, 12972,  9566,\n","        11178,  9554, 24873,  7198,  9391, 12486,  8711,  9346,  7071,\n","        36736,  9693, 12006,  9038, 10279, 36122,  9960,  8405, 10826,\n","        18988, 25998,  9292,  7671,  9465,  7489,  9277, 10137,  9677,\n","         9248,  9912, 12834, 11488, 13417,  7407,  8428,  8137,  9430,\n","        14222, 11356, 10061,  9885, 19265,  9377, 20305,  7991,  9178,\n","         9648,  9133, 10021, 10138, 30315, 21833,  9362,  9301,  9685,\n","        11584,  9447, 42129, 10124,  7532, 17932, 47123, 37544,  9355,\n","        15632,  9124, 10536, 13530, 12204,  9184, 36152,  9673,  9788,\n","         9029, 11764]], dtype=int32)>"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["output_ids = output.numpy().tolist()[0]\n","\n","print(output_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6nLIgsSoBlXL","executionInfo":{"status":"ok","timestamp":1763727570500,"user_tz":-540,"elapsed":4,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"fe77b7fe-aed9-4ed8-a473-92db012d0d0c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[33245, 10114, 12748, 11357, 23879, 39306, 9684, 7884, 10211, 15177, 26421, 387, 17339, 7889, 9908, 15768, 6903, 15386, 8146, 12923, 9228, 18651, 42600, 9564, 17764, 9033, 9199, 14441, 7335, 8704, 12557, 32030, 9510, 18595, 9025, 10571, 25741, 10599, 13229, 9508, 7965, 8425, 33102, 9122, 21240, 9801, 32106, 13579, 12442, 13235, 19430, 8022, 12972, 9566, 11178, 9554, 24873, 7198, 9391, 12486, 8711, 9346, 7071, 36736, 9693, 12006, 9038, 10279, 36122, 9960, 8405, 10826, 18988, 25998, 9292, 7671, 9465, 7489, 9277, 10137, 9677, 9248, 9912, 12834, 11488, 13417, 7407, 8428, 8137, 9430, 14222, 11356, 10061, 9885, 19265, 9377, 20305, 7991, 9178, 9648, 9133, 10021, 10138, 30315, 21833, 9362, 9301, 9685, 11584, 9447, 42129, 10124, 7532, 17932, 47123, 37544, 9355, 15632, 9124, 10536, 13530, 12204, 9184, 36152, 9673, 9788, 9029, 11764]\n"]}]},{"cell_type":"code","source":["print(tokenizer.decode(output_ids))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tek3LrNkBlU2","executionInfo":{"status":"ok","timestamp":1763727570505,"user_tz":-540,"elapsed":4,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"71fb4fbf-4348-4676-89b0-62c740c1f288"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["근육이 커지기 위해서는 무엇보다 규칙적인 생활습관이 중요하다.\n","특히, 아침식사는 단백질과 비타민이 풍부한 과일과 채소를 많이 섭취하는 것이 좋다.\n","또한 하루 30분 이상 충분한 수면을 취하는 것도 도움이 된다.\n","아침 식사를 거르지 않고 규칙적으로 운동을 하면 혈액순환에 도움을 줄 뿐만 아니라 신진대사를 촉진해 체내 노폐물을 배출하고 혈압을 낮춰준다.\n","운동은 하루에 10분 정도만 하는 게 좋으며 운동 후에는 반드시 스트레칭을 통해 근육량을 늘리고 유연성을 높여야 한다.\n","운동 후 바로 잠자리에 드는 것은 피해야 하며 특히 아침에 일어나면 몸이 피곤해지기 때문에 무리하게 움직이면 오히려 역효과가 날 수도 있다.\n","운동을\n"]}]},{"cell_type":"markdown","source":["## Top5 뽑기"],"metadata":{"id":"yMuGupxDBlSF"}},{"cell_type":"code","source":["# \"근육이 커지기 위해서는\"  다음에 생설될 토큰 Top5\n","\n","output = model(input_ids)\n","top5 = tf.math.top_k(output.logits[0, -1], k=5)"],"metadata":{"id":"E48xYfJjBlPw","executionInfo":{"status":"ok","timestamp":1763727570656,"user_tz":-540,"elapsed":150,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["top5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LffQhHL6BlNB","executionInfo":{"status":"ok","timestamp":1763727570674,"user_tz":-540,"elapsed":17,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"b1b0c655-5bab-418f-8095-5d734757ebf5"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TopKV2(values=<tf.Tensor: shape=(5,), dtype=float32, numpy=\n","array([9.955053 , 9.470137 , 9.1222105, 9.1037855, 9.0559435],\n","      dtype=float32)>, indices=<tf.Tensor: shape=(5,), dtype=int32, numpy=array([23879, 12201, 11488, 14564, 20030], dtype=int32)>)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["tokenizer.convert_ids_to_tokens(top5.indices.numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Zr7tfPCBlKW","executionInfo":{"status":"ok","timestamp":1763727570679,"user_tz":-540,"elapsed":4,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"4550ab8d-d787-43e0-c59d-1c517afeda62"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['▁무엇보다', '▁우선', '▁반드시', '▁피부', '▁무엇보다도']"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["## Top5 로 문장 생성하기"],"metadata":{"id":"TFT-tVlSBlHl"}},{"cell_type":"code","source":["sent = '근육이 커지기 위해서는'\n","input_ids = tokenizer.encode(sent)\n","\n","while len(input_ids) < 50:\n","  output = model(np.array([input_ids]))\n","  # Top5 단어들 추출\n","  top5 = tf.math.top_k(output.logits[0, -1], k=5)\n","  # 위 Top5 단어들 중 랜덤으로 다음 단어 선택.\n","  token_id = random.choice(top5.indices.numpy())\n","  input_ids.append(token_id)\n","\n","print(tokenizer.decode(input_ids))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kd3aq0DkBlE6","executionInfo":{"status":"ok","timestamp":1763727579150,"user_tz":-540,"elapsed":8470,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"8a6119e0-5c54-426c-8a33-6de25e6b428c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["근육이 커지기 위해서는 피부 타입, 각질, 주름 등을 꼼꼼히 살펴서 피부 상태를 확인해야 합니다.\n","또 평소에는 자외선 차단과 함께 자외선 차단지수 10점 만점으로 기초 화장품의 사용을 줄여주시는 것도 좋지만 평소에도 자외선이 강한 날에\n"]}]},{"cell_type":"code","source":["# 근육이 커지기 위해서는 반드시 영양소를 보충할 필요하다. 영양소가 부족해 살이 찔 수 있다는 건 누구나 알지만 그걸 방치해두기 때문에 살이 찔 확률이 높아진다고 전문가들이 경고하는 것과 같은 원리다.\n","# 그렇게 살을 뺀 후엔 살이"],"metadata":{"id":"ibmpnt_XBlCe","executionInfo":{"status":"ok","timestamp":1763727579153,"user_tz":-540,"elapsed":1,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# 근육이 커지기 위해서는 반드시 건강하고 튼튼한 식품을 선택하는 것이 중요하다\"며, \"최근의 영양소 파괴에 의해 체지방이 증가하고 지방세포의 생착률 역시 감소한 상태여서 영양소를 파괴한 음식을 피하는 것이 가장 효과적이며, 체지방이 많이\n","\n"],"metadata":{"id":"wSaC7FIfBk_v","executionInfo":{"status":"ok","timestamp":1763727579155,"user_tz":-540,"elapsed":1,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# 근육이 커지기 위해서는 무엇보다 면역력 제고에 도움이 돼 면역력을 높여줘야만 한다.\"고 조언한다. 면역력의 핵심은 '생명과 활력의 조화'이다.\n","# 이러면 자연스런 건강의 길도 열린다\n","# 건강한 몸을 유지하는 것이 가장 중요하다.\n","# 이"],"metadata":{"id":"pw7ITkNrBk9Z","executionInfo":{"status":"ok","timestamp":1763727579157,"user_tz":-540,"elapsed":1,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# GPT-2 를 이용한 챗봇"],"metadata":{"id":"vl1etpn4Mzpx"}},{"cell_type":"code","source":["import numpy as np\n","import random\n","import tensorflow as tf\n","from transformers import AutoTokenizer # 특정모델에 알맞은 tokenizer 를 자동으로 불러오는 유틸리티 클래스\n","from transformers import TFGPT2LMHeadModel"],"metadata":{"id":"KMQFEvFnaT0q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## KoGPT-2 의 모델과 토크나이저"],"metadata":{"id":"PXW6yMnpMzl3"}},{"cell_type":"code","source":["model = TFGPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2', from_pt=True)\n","tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2',\n","                                          bos_token='</s>', eos_token='</s>', pad_token='<pad>')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d7yHQql5Mzg0","executionInfo":{"status":"ok","timestamp":1763727582717,"user_tz":-540,"elapsed":3559,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"59933e82-6375-48a6-833e-e30a963eaf8c"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.9.attn.masked_bias', 'lm_head.weight', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.10.attn.masked_bias']\n","- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"]}]},{"cell_type":"code","source":["print(tokenizer.bos_token_id)  # 1\n","print(tokenizer.eos_token_id)  # 1\n","print(tokenizer.pad_token_id)  # 3\n","print('-' * 10)\n","print(tokenizer.decode(1))\n","print(tokenizer.decode(2))\n","print(tokenizer.decode(3))\n","print(tokenizer.decode(4))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DC0MCVvPNZNs","executionInfo":{"status":"ok","timestamp":1763727582727,"user_tz":-540,"elapsed":8,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"8c4bcc5a-64c7-465a-cd17-5bc59a4048a2"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","1\n","3\n","----------\n","</s>\n","<usr>\n","<pad>\n","<sys>\n"]}]},{"cell_type":"markdown","source":["## 챗봇 데이터 로드"],"metadata":{"id":"ZhP_RGZFNv42"}},{"cell_type":"code","source":["import pandas as pd\n","import tqdm\n","import urllib.request"],"metadata":{"id":"-LKu83qMNjVV","executionInfo":{"status":"ok","timestamp":1763727582737,"user_tz":-540,"elapsed":1,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["urllib.request.urlretrieve(\"https://raw.githubusercontent.com/songys/Chatbot_data/master/ChatbotData.csv\", filename=\"ChatBotData.csv\")\n","train_data = pd.read_csv('ChatBotData.csv')\n","print('챗봇 데이터의 개수 :', len(train_data))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z6uX5vytBk6x","executionInfo":{"status":"ok","timestamp":1763727583285,"user_tz":-540,"elapsed":547,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"e3519510-1811-4c3b-e4eb-293007af0811"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["챗봇 데이터의 개수 : 11823\n"]}]},{"cell_type":"code","source":["train_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"dp-IUjLyBk37","executionInfo":{"status":"ok","timestamp":1763727583314,"user_tz":-540,"elapsed":30,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"30b308b5-66a8-40db-dd9a-e64d422d3149"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                             Q                         A  label\n","0                       12시 땡!                하루가 또 가네요.      0\n","1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n","2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n","3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n","4                      PPL 심하네                눈살이 찌푸려지죠.      0\n","...                        ...                       ...    ...\n","11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n","11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n","11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n","11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n","11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n","\n","[11823 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-053fcb61-0f3c-4dd5-bc6b-8bee65fe1131\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Q</th>\n","      <th>A</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>12시 땡!</td>\n","      <td>하루가 또 가네요.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1지망 학교 떨어졌어</td>\n","      <td>위로해 드립니다.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3박4일 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3박4일 정도 놀러가고 싶다</td>\n","      <td>여행은 언제나 좋죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>PPL 심하네</td>\n","      <td>눈살이 찌푸려지죠.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>11818</th>\n","      <td>훔쳐보는 것도 눈치 보임.</td>\n","      <td>티가 나니까 눈치가 보이는 거죠!</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>11819</th>\n","      <td>훔쳐보는 것도 눈치 보임.</td>\n","      <td>훔쳐보는 거 티나나봐요.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>11820</th>\n","      <td>흑기사 해주는 짝남.</td>\n","      <td>설렜겠어요.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>11821</th>\n","      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n","      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>11822</th>\n","      <td>힘들어서 결혼할까봐</td>\n","      <td>도피성 결혼은 하지 않길 바라요.</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>11823 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-053fcb61-0f3c-4dd5-bc6b-8bee65fe1131')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-053fcb61-0f3c-4dd5-bc6b-8bee65fe1131 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-053fcb61-0f3c-4dd5-bc6b-8bee65fe1131');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-07908cc3-4437-4514-9a8e-dc380b39b55d\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-07908cc3-4437-4514-9a8e-dc380b39b55d')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-07908cc3-4437-4514-9a8e-dc380b39b55d button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_cf1fd1bc-6290-468b-91a4-a2d8f6cfcd7b\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_data')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_cf1fd1bc-6290-468b-91a4-a2d8f6cfcd7b button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('train_data');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"train_data","summary":"{\n  \"name\": \"train_data\",\n  \"rows\": 11823,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11662,\n        \"samples\": [\n          \"\\uc0ac\\ub791\\ud558\\ub294 \\uc0ac\\ub78c \\uc78a\\ub294 \\ubc95\",\n          \"\\uc220 \\uc548 \\uba39\\uc73c\\uba74 \\uce5c\\uad6c\\ub791 \\ubb50\\ud558\\uc9c0\",\n          \"\\uc9dd\\ub0a8\\uc774 \\uace0\\uc2dc\\uc0dd\\uc774\\uba74 \\uae30\\ub2e4\\ub824\\uc57c \\ud558\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7779,\n        \"samples\": [\n          \"\\uc720\\uba38\\ucf54\\ub4dc\\uac00 \\ub9de\\ub294 \\uc0ac\\ub78c\\uc744 \\ucc3e\\uc544\\ubcf4\\uc138\\uc694.\",\n          \"\\uc5ec\\ud589\\uc744 \\ub5a0\\ub098 \\ubcf4\\uc138\\uc694.\",\n          \"\\ud589\\ubcf5\\ud560 \\uac70\\ub77c \\uc0dd\\uac01\\ud574\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["## 데이터 전처리"],"metadata":{"id":"79Ga2DpMBk1l"}},{"cell_type":"code","source":["def get_chat_data():\n","  for question, answer in zip(train_data['Q'].to_list(), train_data['A'].to_list()):\n","    # question 은 User 메세지로 -> <usr> 토큰으로 시작\n","    # answer 는 system 메세지로 -> <sys> 토큰으로 시작\n","    sent = tokenizer.encode('<usr>' + question + '<sys>' + answer)\n","    yield [tokenizer.bos_token_id] + sent + [tokenizer.eos_token_id]\n"],"metadata":{"id":"Pv7bkLlSBky4","executionInfo":{"status":"ok","timestamp":1763727583334,"user_tz":-540,"elapsed":18,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","dataset = tf.data.Dataset.from_generator(get_chat_data, output_types=tf.int32)\n","\n","# batch_size 만큼의 배치로 데이터 구성, 패딩토큰으로 패딩\n","dataset = dataset.padded_batch(batch_size=batch_size, padded_shapes=(None,), padding_values=tokenizer.pad_token_id)\n"],"metadata":{"id":"R2ckoEFvBkwh","executionInfo":{"status":"ok","timestamp":1763727583363,"user_tz":-540,"elapsed":28,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["for batch in dataset:\n","  print(batch)\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LkuV5VonTW48","executionInfo":{"status":"ok","timestamp":1763727583471,"user_tz":-540,"elapsed":109,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"6e28540d-480c-4433-f393-bffc081a6502"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[[    1     2  9349  7888   739  7318   376     4 12557  6824  9108  9028\n","   7098 25856     1     3     3     3     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2  9020  8263  7497 10192 11615  8210  8006     4 12422  8711\n","   9535  7483 12521     1     3     3     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2  9085  7597   395  8149 10624  7397 24224 13358  7182     4\n","  12079  8135 16899  9677  8234   389     1     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2  9085  7597   395  8149  9465 10624  7397 24224 13358  7182\n","      4 12079  8135 16899  9677  8234   389     1     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2  9943   422   418  9327  8702  7098     4  9847 16912 18328\n","   8671  7415  8263  8234   389     1     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2  9815   410 21249 10174  6824  8210  8006     4  9427 11056\n","  11594 10137 10556  9266  8711 25856     1     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2  9815   410 21249  9183  7249     4  9427 11056 11594 10137\n","  10556  9266  8711 25856     1     3     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2  9815 37655  9622  8619 10401  9183  9328   216     4  9443\n","  29490  9846  9788  9341 25856     1     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2  9815 37655 10135  7066 39488  9122  9050  9668 16576  9277\n","   9044     4 15148 19658  9098  7652  7801 25856     1     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2  9815 37655 10135  7066  7692 11848  9042  7019 20284  7254\n","      4 15148 19658  9098  7652  7801 25856     1     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2  9815 37655 18381  9063  7489 29615  9054 15730 29452  8030\n","      4 33254 10300 23775 25856     1     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 19319 48397  8711     4  9022 19858 27031  9122  8046 25856\n","      1     3     3     3     3     3     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 19319 46651 27481 48397  8711     4  9022 19858 27031  9122\n","   8046 25856     1     3     3     3     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 19319  8135  9749 10225  6866  9677  7182     4  9749  9589\n","  20540  7801 25856     1     3     3     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 17230 17429  9160  8098     4 10855  8135  9427 35813  9122\n","   8046 25856     1     3     3     3     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 47980 22227 26992  7058  7182     4 26992  8137  9376  8737\n","   8236  7801 25856     1     3     3     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 26629 23799   739  8308  7304 10174  8707     4  9105  7788\n","  16346  6889  9282  8400  7601  9078  7801 25856     1     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 15983  7673 24648  6889 25880  8006     4 16173 15582 46439\n","  35557  6889 12252  7801 25856     1     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 15983  7673 24648 15010 10926  6853 27511     4 16173 15582\n","  46439 35557  6889 12252  7801 25856     1     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 15983  7692 12371  9564 16409  9016     4  9536  9271  9052\n","   9267 27545  8711  7661 25856     1     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 15983  7692 36684  7220  9244  6958  9539  7478  6872  8006\n","      4 46503  9024  7801  8084   376     1     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 15983  7692 26873  9050  7177     4  9536  9271  9052  9267\n","  27545  8711  7661 25856     1     3     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2  9278 20861  9193   739  7570 47804     4  9278 20861 32392\n","  10070 10828 25856  9105 12114  9094 12191 12700 31279  8702 38887 15148\n","  35441  9328  9109  7801 25856     1]\n"," [    1     2 10464 12079  9028  9926  9651  8006     4  9586 27820  9432\n","  23100 21833 14247 29462  7801 25856     1     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 10464 12079 17577     4  9586 27820  9432 23100 21833 14247\n","  29462  7801 25856     1     3     3     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 10464 12079 42076  9340   406     4  9586 27820  9432 23100\n","  21833 14247 29462  7801 25856     1     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 10464  9341   406     4  9265  7470  9659  9701 11389 11676\n","   7177   387  9265  7380 11120  8711 10764 11389  9728 12245 22238  9341\n","   8084     1     3     3     3     3]\n"," [    1     2 10464 10143  9666   739  8244     4  9265  7470  9659  9701\n","  11389 11676  7177   387  9265  7380 11120  8711 10764 11389  9728 12245\n","  22238  9341  8084     1     3     3]\n"," [    1     2 10464 18264 12079  6826  9016     4  9267 25772  8267 25012\n","   9069  6872  7098 25856     1     3     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 10464  7285 10056 25799     4  9265  7235 25856     1     3\n","      3     3     3     3     3     3     3     3     3     3     3     3\n","      3     3     3     3     3     3]\n"," [    1     2 10464  9136  7380  9071  7513  8711     4  9054  7285  9117\n","   7703  7788 11120  8705 14553 10667  8718  7055  7661 25856     1     3\n","      3     3     3     3     3     3]\n"," [    1     2 10464  9136  7380  9071  7513  8711  8210  8006     4  9054\n","   7285  9117  7703  7788 11120  8705 14553 10667  8718  7055  7661 25856\n","      1     3     3     3     3     3]], shape=(32, 30), dtype=int32)\n"]}]},{"cell_type":"code","source":["# 첫번째 배치의 첫번째 샘플\n","print(tokenizer.decode(batch[0]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fK-LLXHqBkuQ","executionInfo":{"status":"ok","timestamp":1763727583476,"user_tz":-540,"elapsed":4,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"fefb8109-875d-4b81-ee97-d581127f1b96"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["</s><usr> 12시 땡!<sys> 하루가 또 가네요.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"]}]},{"cell_type":"markdown","source":["## 챗봇 학습하기"],"metadata":{"id":"-4KgGzZ4Tptb"}},{"cell_type":"code","source":["# 옵티마이저 결정\n","adam = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)\n","\n","# 전체 데이터의 개수를 배치 크기로 나누면 하나의 에포크에서 실행되는 학습 횟수가 계산됨.\n","steps = len(train_data) // batch_size + 1\n","\n","EPOCHS = 3"],"metadata":{"id":"2R23zal-Bkrb","executionInfo":{"status":"ok","timestamp":1763727583490,"user_tz":-540,"elapsed":13,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# tf.GradientTape\n","#   https://www.tensorflow.org/api_docs/python/tf/GradientTape\n","#   Record operations for automatic differentiation.  (자동미분)\n","\n","#   텐서플로는 자동 미분(주어진 입력 변수에 대한 연산의 그래디언트(gradient)를 계산하는 것)을\n","#   위한 tf.GradientTape API를 제공합니다.\n","#   tf.GradientTape는 컨텍스트(context) 안에서 실행된 모든 연산을 테이프(tape)에 \"기록\"합니다.\n","#   그 다음 텐서플로는 후진 방식 자동 미분(reverse mode differentiation)을 사용해\n","#   테이프에 \"기록된\" 연산의 그래디언트를 계산합니다.\n","\n","# tape.gradient(target, sources)를 통해,\n","#     target: 미분 대상 (예: 손실 함수)\n","#     sources: 미분할 변수들\n","\n","# 참고: 그레디언트 및 자동 미분 소개, https://www.tensorflow.org/guide/autodiff?hl=ko\n"],"metadata":{"id":"ZatllkApUFEy","executionInfo":{"status":"ok","timestamp":1763727583493,"user_tz":-540,"elapsed":1,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["for epoch in range(EPOCHS):\n","  epoch_loss = 0\n","\n","  for batch in tqdm.tqdm_notebook(dataset, total=steps):\n","    with tf.GradientTape() as tape:  # 실행된 모든 연산이 tape 에 기록\n","      result = model(batch, labels=batch)\n","      loss = result[0]\n","      batch_loss = tf.reduce_mean(loss)\n","\n","    grads = tape.gradient(batch_loss, model.trainable_variables)  # 기울기 계산 (미분)\n","    adam.apply_gradients(zip(grads, model.trainable_variables))  # 기울기 적용\n","    epoch_loss += batch_loss / steps\n","\n","  print('[Epoch: {:>4}] loss = {:>.9}'.format(epoch + 1, epoch_loss))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":549,"referenced_widgets":["8a82260ade0248db8f123070594f5456","5d85e696327048d5bf681ddd1e66548a","d271c42d4f1c4a2a9b6e3e9c13c115b1","21ab36aa62b34b9c928c42a52d828bce","329c988ebbda40c1b59945f58836b932","5839b4a4244544b0982232b463e14f98","15c322047292425898a21854370a9905","5450083b1bf94925ba8f653131078f8d","3419f53a9eb54de6851fcc9a971ee5b4","7ba64c89ba4a4f66824bfd52cc548eb6","27d6658e52ed44b099c208872357bd7e"]},"id":"uVFEj4g_UFCE","executionInfo":{"status":"error","timestamp":1763727852849,"user_tz":-540,"elapsed":269346,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}},"outputId":"fa1ec5b6-d8b5-4f36-8b1c-a923138a1aba"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1111581542.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  for batch in tqdm.tqdm_notebook(dataset, total=steps):\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/370 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a82260ade0248db8f123070594f5456"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7d2b7c686200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n","WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7d2b7c686200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"{{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[32,51200,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:BatchMatMulV2] name: ","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1111581542.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 기울기 계산 (미분)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0madam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 기울기 적용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1064\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_BatchMatMulV2\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1851\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m       )\n\u001b[0;32m-> 1853\u001b[0;31m       grad_y = math_ops.matmul(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madjoint_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6004\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6005\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6006\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__BatchMatMulV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} OOM when allocating tensor with shape[32,51200,768] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:BatchMatMulV2] name: "]}]},{"cell_type":"markdown","source":["## 챗봇 실행"],"metadata":{"id":"NyhktBGrUE--"}},{"cell_type":"code","source":["text = '오늘도 좋은 하루!'\n","\n","sent = '<usr>' + text + '<sys>'  # 챗봇더러 <sys> 이후의 시퀀스를 생성하도록 함.\n","\n","input_ids = [tokenizer.bos_token_id] + tokenizer.encode(sent)\n","input_ids = tf.convert_to_tensor([input_ids])\n","print('정수 인코딩 후 :', input_ids)\n","print('정수 인코딩을 재복원 :', tokenizer.decode(input_ids[0]))\n","\n","# 정수 인코딩 후 : tf.Tensor([[    1     2 10070  7235 10586 12557   376     4]], shape=(1, 8), dtype=int32)\n","# 정수 인코딩을 재복원 : </s><usr> 오늘도 좋은 하루!<sys>"],"metadata":{"id":"okVDqy8fUE7C","executionInfo":{"status":"aborted","timestamp":1763727852850,"user_tz":-540,"elapsed":346186,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output = model.generate(input_ids, max_length=50,\n","               early_stopping=True, eos_token_id=tokenizer.eos_token_id)\n","\n","decoded_sentence = tokenizer.decode(output[0].numpy().tolist())\n","print(decoded_sentence)\n","\n","# </s><usr> 오늘도 좋은 하루!<sys> 오늘도 좋은 하루네요.</s>"],"metadata":{"id":"T8SjB1qIUE2D","executionInfo":{"status":"aborted","timestamp":1763727852852,"user_tz":-540,"elapsed":346188,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(decoded_sentence.split('<sys> ')[1].replace('</s>', ''))\n","\n","# 오늘도 좋은 하루네요."],"metadata":{"id":"7G-EbaGfXiCk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output = model.generate(input_ids, max_length=50, do_sample=True, top_k=10)\n","decoded_sentence = tokenizer.decode(output[0].numpy().tolist())\n","print(decoded_sentence.split('<sys> ')[1].replace('</s>', ''))"],"metadata":{"id":"bQDVg613UEl8","executionInfo":{"status":"aborted","timestamp":1763727852860,"user_tz":-540,"elapsed":1,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def return_answer_by_chatbot(user_text):\n","  sent = '<usr>' + user_text + '<sys>'\n","  input_ids = [tokenizer.bos_token_id] + tokenizer.encode(sent)\n","  input_ids = tf.convert_to_tensor([input_ids])\n","  output = model.generate(input_ids, max_length=50, do_sample=True, top_k=20)\n","  sentence = tokenizer.decode(output[0].numpy().tolist())\n","  chatbot_response = sentence.split('<sys> ')[1].replace('</s>', '')\n","  return chatbot_response"],"metadata":{"id":"5rfvuBY4BkpF","executionInfo":{"status":"aborted","timestamp":1763727852861,"user_tz":-540,"elapsed":346197,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sentences = [\n","    '안녕! 반가워~',\n","    '너는 누구야?',\n","    '너무 심심한데 나랑 놀자',\n","    '영화 해리포터 재밌어?',\n","    '너 딥 러닝 잘해?',\n","]"],"metadata":{"id":"I1yiQQGcBkmu","executionInfo":{"status":"aborted","timestamp":1763727852873,"user_tz":-540,"elapsed":346208,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for sentence in sentences:\n","  print(f'▶{sentence}')\n","  print(f'▷{return_answer_by_chatbot(sentence)}')\n","  print()"],"metadata":{"id":"x_KywrRcBkkB","executionInfo":{"status":"aborted","timestamp":1763727852902,"user_tz":-540,"elapsed":2,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"clmQz26xBkhQ","executionInfo":{"status":"aborted","timestamp":1763727852905,"user_tz":-540,"elapsed":346240,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"36j1Cl4KBkeM","executionInfo":{"status":"aborted","timestamp":1763727852907,"user_tz":-540,"elapsed":346242,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NuxRcuXpBhg5","executionInfo":{"status":"aborted","timestamp":1763727852908,"user_tz":-540,"elapsed":346243,"user":{"displayName":"Sam Coding","userId":"14578619261721572933"}}},"outputs":[],"source":[]}]}